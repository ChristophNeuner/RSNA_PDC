{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../fastai/old/') #fastai version 0.7\n",
    "#sys.path.append('../../fastai/') #fastai version 1\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "import torchvision.models as pytorch_models\n",
    "\n",
    "import pdb\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from matplotlib.patches import Rectangle\n",
    "import png\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as mcolors\n",
    "from cycler import cycler\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "dp = Path('../../datasets/RSNA_PDC/')\n",
    "\n",
    "DICOMS = dp/'stage_2_train_images'\n",
    "\n",
    "PNGS = dp/'train2_png'\n",
    "PNGS.mkdir(exist_ok=True)\n",
    "\n",
    "TEST_ONE = 'test1_png'\n",
    "TEST_TWO = 'test2_png'\n",
    "\n",
    "SUBMISSIONS = dp/'submissions'\n",
    "SUBMISSIONS.mkdir(exist_ok=True)\n",
    "\n",
    "f_model=resnet34\n",
    "#f_model = pytorch_models.inception_v3(pretrained=True)\n",
    "\n",
    "sz=512\n",
    "bs=16\n",
    "\n",
    "validation_percentage = 0.05\n",
    "\n",
    "original_image_size = 1024\n",
    "\n",
    "num_colr = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ObjDetDataset(Dataset):\n",
    "    def __init__(self, ds, y2): \n",
    "        self.ds = ds \n",
    "        self.y2 = y2\n",
    "    \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.ds[i]\n",
    "        return (x, (y, self.y2[i]))\n",
    "\n",
    "\n",
    "class ConcatLblDataset(Dataset):\n",
    "    def __init__(self, ds, y2):\n",
    "        self.ds,self.y2 = ds,y2\n",
    "        self.sz = ds.sz\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x,y = self.ds[i]\n",
    "        return (x, (y,self.y2[i]))\n",
    "\n",
    "class ConcatLblDataset_TestData(Dataset):\n",
    "    def __init__(self, ds, y_tuple_placeholder):\n",
    "        self.ds,self.y = ds,y_tuple_placeholder\n",
    "        self.sz = ds.sz\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x = self.ds.get_x(i)\n",
    "        x = self.ds.transform(x)\n",
    "        return (x, (self.y))\n",
    "    \n",
    "class StdConv(nn.Module):\n",
    "    def __init__(self, nin, nout, stride=2, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, x): return self.drop(self.bn(F.relu(self.conv(x))))\n",
    "        \n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, k, nin, bias):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.oconv1 = nn.Conv2d(nin, (len(id2cat)+1)*k, 3, padding=1)\n",
    "        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)\n",
    "        self.oconv1.bias.data.zero_().add_(bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return [flatten_conv(self.oconv1(x), self.k),\n",
    "                flatten_conv(self.oconv2(x), self.k)]\n",
    "\n",
    "\n",
    "class SSD_MultiHead(nn.Module):\n",
    "    def __init__(self, k, bias, drop):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.sconv1 = StdConv(512,256, drop=drop)\n",
    "        self.sconv2 = StdConv(256,256, drop=drop)\n",
    "        self.sconv3 = StdConv(256,256, drop=drop)\n",
    "        self.out0 = OutConv(k, 256, bias)\n",
    "        self.out1 = OutConv(k, 256, bias)\n",
    "        self.out2 = OutConv(k, 256, bias)\n",
    "        self.out3 = OutConv(k, 256, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv1(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[0]) # adaptive maxpool for 1st size of anchors\n",
    "        o1c,o1l = self.out1(x)\n",
    "        x = self.sconv2(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[1]) # adaptive maxpool for 2nd size of anchors\n",
    "        o2c,o2l = self.out2(x) \n",
    "        x = self.sconv3(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[2]) # adaptive maxpool for 3rd size of anchors\n",
    "        o3c,o3l = self.out3(x)\n",
    "#         return [o1c, o1l]\n",
    "        return [torch.cat([o1c,o2c,o3c], dim=1),\n",
    "                torch.cat([o1l,o2l,o3l], dim=1)]\n",
    "\n",
    "\n",
    "class BCE_Loss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, pred, targ):\n",
    "        t = one_hot_embedding(targ, self.num_classes+1)\n",
    "        t = V(t[:,:-1].contiguous())#.cpu()\n",
    "        x = pred[:,:-1]\n",
    "        w = self.get_weight(x,t)\n",
    "        #return F.binary_cross_entropy_with_logits(x, t, w, size_average=False)/self.num_classes\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, reduction='sum')/self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t): return None\n",
    "\n",
    "\n",
    "class FocalLoss(BCE_Loss):\n",
    "    def get_weight(self,x,t):\n",
    "        alpha,gamma = 0.25,1\n",
    "        p = x.sigmoid()\n",
    "        pt = p*t + (1-p)*(1-t)\n",
    "        w = alpha*t + (1-alpha)*(1-t)\n",
    "        return w * (1-pt).pow(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    ax.get_yaxis().set_visible(True)\n",
    "    return ax\n",
    "\n",
    "def from_dicom_to_png(dicom_path, png_path):\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "    shape = ds.pixel_array.shape\n",
    "    # Convert to float to avoid overflow or underflow losses.\n",
    "    image_2d = ds.pixel_array.astype(float)\n",
    "    # Rescaling grey scale between 0-255\n",
    "    image_2d_scaled = (np.maximum(image_2d,0) / image_2d.max()) * 255.0\n",
    "    # Convert to uint\n",
    "    image_2d_scaled = np.uint8(image_2d_scaled)\n",
    "    # Write the PNG file\n",
    "    with open(png_path, 'wb') as png_file:\n",
    "        w = png.Writer(shape[1], shape[0], greyscale=True)\n",
    "        w.write(png_file, image_2d_scaled)\n",
    "        \n",
    "        \n",
    "def hw_bb(row): return np.array([row['y'], row['x'], row['height']+row['y'], row['width']+row['x']])\n",
    "\n",
    "##[x_upper_left, y_upper_left, width, height]\n",
    "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])\n",
    "\n",
    "def parse_data(df):\n",
    "    \"\"\"\n",
    "    Method to read a CSV file (Pandas dataframe) and parse the \n",
    "    data into the following nested dictionary:\n",
    "\n",
    "      parsed = {\n",
    "        \n",
    "        'patientId-00': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        },\n",
    "        'patientId-01': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        }, ...\n",
    "\n",
    "      }\n",
    "\n",
    "    \"\"\"\n",
    "    parsed = collections.defaultdict(lambda:{'dicom': None,\n",
    "                                        'png': None,     \n",
    "                                        'label': None,\n",
    "                                        'boxes': []})\n",
    "    for n, row in df.iterrows():\n",
    "        # --- Initialize patient entry into parsed \n",
    "        pid = row['patientId']\n",
    "        parsed[pid]['dicom'] = str(DICOMS/f'{pid}.dcm')\n",
    "        parsed[pid]['png'] = str(PNGS/f'{pid}.png')\n",
    "        parsed[pid]['label'] = row['Target']\n",
    "        parsed[pid]['boxes'].append(hw_bb(row))\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def get_lrg(b):\n",
    "    if not b: raise Exception()\n",
    "    b = sorted(b, key=lambda x: np.product(x[-2:]-x[:2]), reverse=True)\n",
    "    return [b[0]]\n",
    "\n",
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    #ax.get_xaxis().set_visible(False)\n",
    "    #ax.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def draw_rect(ax, b, col='white'):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=col, lw=2))\n",
    "    draw_outline(patch, 4)\n",
    "    \n",
    "def draw_text(ax, xy, txt, sz=14, col='white'):\n",
    "    text = ax.text(*xy, txt,\n",
    "        verticalalignment='top', color=col, fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)\n",
    "    \n",
    "def draw_im(im, ann, ax=None):\n",
    "    ax = show_img(im, figsize=(12,6), ax=ax)\n",
    "    l = cats[ann['label']]\n",
    "    for b in ann['boxes']:\n",
    "        b = bb_hw(b)\n",
    "        draw_rect(ax, b)\n",
    "        draw_text(ax, b[:2], l, sz=16)\n",
    "        \n",
    "def draw_idx(im_a, ax=None):\n",
    "    dcm_data = pydicom.read_file(im_a['dicom'])\n",
    "    im = dcm_data.pixel_array\n",
    "    draw_im(im, im_a, ax=ax)\n",
    "    \n",
    "def from_dicom_to_png(parsed):\n",
    "    for k, v in parsed.items():\n",
    "        dcm_data = pydicom.read_file(v['dicom'])\n",
    "        im = dcm_data.pixel_array\n",
    "        imageio.imwrite(v['png'], im)\n",
    "\n",
    "\n",
    "\n",
    "def show_ground_truth(ax, im, bbox, clas=None, prs=None, thresh=0.3):\n",
    "    bb = [bb_hw(o) for o in bbox.reshape(-1,4)]\n",
    "    if prs is None:  prs  = [None]*len(bb)\n",
    "    if clas is None: clas = [None]*len(bb)\n",
    "    ax = show_img(im, ax=ax)\n",
    "    for i,(b,c,pr) in enumerate(zip(bb, clas, prs)):\n",
    "        if((b[2]>0) and (pr is None or pr > thresh)):\n",
    "            draw_rect(ax, b, col=colr_list[i%num_colr])\n",
    "            txt = f'{i}: '\n",
    "            if c is not None: txt += ('bg' if c==len(id2cat) else id2cat[c])\n",
    "            if pr is not None: txt += f' {pr:.2f}'\n",
    "            draw_text(ax, b[:2], txt, col=colr_list[i%num_colr])\n",
    "\n",
    "\n",
    "def get_cmap(N):\n",
    "    color_norm  = mcolors.Normalize(vmin=0, vmax=N-1)\n",
    "    return cmx.ScalarMappable(norm=color_norm, cmap='Set3').to_rgba\n",
    "            \n",
    "cmap = get_cmap(num_colr)\n",
    "colr_list = [cmap(float(x)) for x in range(num_colr)]\n",
    "            \n",
    "\n",
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2, ctr+hw/2], dim=1)\n",
    "\n",
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs,-1,nf//k)\n",
    "\n",
    "    \n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]\n",
    "\n",
    "\n",
    "def intersect(box_a, box_b):\n",
    "    max_xy = torch.min(box_a[:, None, 2:], box_b[None, :, 2:])\n",
    "    min_xy = torch.max(box_a[:, None, :2], box_b[None, :, :2])\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[:, :, 0] * inter[:, :, 1]\n",
    "\n",
    "def box_sz(b): return ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))\n",
    "\n",
    "def jaccard(box_a, box_b):\n",
    "    inter = intersect(box_a, box_b)\n",
    "    union = box_sz(box_a).unsqueeze(1) + box_sz(box_b).unsqueeze(0) - inter\n",
    "    return inter / union\n",
    "\n",
    "def get_y(bbox,clas):\n",
    "    bbox = bbox.view(-1,4)/sz\n",
    "    bb_keep = ((bbox[:,2]-bbox[:,0])>0).nonzero()[:,0]\n",
    "    return bbox[bb_keep],clas[bb_keep]\n",
    "\n",
    "def actn_to_bb(actn, anchors):\n",
    "    actn_bbs = torch.tanh(actn)\n",
    "    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]\n",
    "    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n",
    "    return hw2corners(actn_centers, actn_hw)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def ssd_1_loss(b_c, b_bb, bbox, clas, print_it=False):\n",
    "    bbox,clas = get_y(bbox,clas)\n",
    "    a_ic = actn_to_bb(b_bb, anchors)\n",
    "    overlaps = jaccard(bbox.data, anchor_cnr.data)\n",
    "    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)\n",
    "    gt_clas = clas[gt_idx]\n",
    "    pos = gt_overlap > 0.4\n",
    "    pos_idx = torch.nonzero(pos)[:,0]\n",
    "    gt_clas[1-pos] = len(id2cat)\n",
    "    gt_bbox = bbox[gt_idx]\n",
    "    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "    clas_loss  = loss_f(b_c, gt_clas)\n",
    "    return loc_loss, clas_loss\n",
    "\n",
    "def ssd_loss(pred,targ, print_it=False):\n",
    "    lcs,lls = 0.,0.\n",
    "    for b_c,b_bb,bbox,clas in zip(*pred,*targ):\n",
    "        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,loss_function,print_it)\n",
    "        lls += loc_loss\n",
    "        lcs += clas_loss\n",
    "    if print_it: print(f'loc: {lls.data[0]}, clas: {lcs.data[0]}')\n",
    "    return lls+lcs\n",
    "\n",
    "def torch_gt(ax, ima, bbox, clas, prs=None, thresh=0.4):\n",
    "    return show_ground_truth(ax, ima, to_np((bbox*sz).long()),\n",
    "         to_np(clas), to_np(prs) if prs is not None else None, thresh)\n",
    "\n",
    "def plot_results(thresh):\n",
    "    x,y = next(iter(md_mbb_csv.val_dl))\n",
    "    y = V(y)\n",
    "    batch = learn.model(V(x))\n",
    "    b_clas,b_bb = batch\n",
    "\n",
    "    x = to_np(x)\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    for idx,ax in enumerate(axes.flat):\n",
    "        ima=md_mbb_csv.val_ds.ds.denorm(x)[idx]\n",
    "        bbox,clas = get_y(y[0][idx], y[1][idx])\n",
    "        a_ic = actn_to_bb(b_bb[idx], anchors)\n",
    "        clas_pr, clas_ids = b_clas[idx].max(1)\n",
    "        clas_pr = clas_pr.sigmoid()\n",
    "        torch_gt(ax, ima, a_ic, clas_ids, clas_pr, clas_pr.max().data[0]*thresh)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "###non max suppression\n",
    "def nms(boxes, scores, overlap=0.5, top_k=100):\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    if boxes.numel() == 0: return keep\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    v, idx = scores.sort(0)  # sort in ascending order\n",
    "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
    "    xx1 = boxes.new()\n",
    "    yy1 = boxes.new()\n",
    "    xx2 = boxes.new()\n",
    "    yy2 = boxes.new()\n",
    "    w = boxes.new()\n",
    "    h = boxes.new()\n",
    "\n",
    "    count = 0\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        if idx.size(0) == 1: break\n",
    "        idx = idx[:-1]  # remove kept element from view\n",
    "        # load bboxes of next highest vals\n",
    "        torch.index_select(x1, 0, idx, out=xx1)\n",
    "        torch.index_select(y1, 0, idx, out=yy1)\n",
    "        torch.index_select(x2, 0, idx, out=xx2)\n",
    "        torch.index_select(y2, 0, idx, out=yy2)\n",
    "        # store element-wise max with next highest score\n",
    "        xx1 = torch.clamp(xx1, min=x1[i])\n",
    "        yy1 = torch.clamp(yy1, min=y1[i])\n",
    "        xx2 = torch.clamp(xx2, max=x2[i])\n",
    "        yy2 = torch.clamp(yy2, max=y2[i])\n",
    "        w.resize_as_(xx2)\n",
    "        h.resize_as_(yy2)\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        # check sizes of xx1 and xx2.. after each iteration\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "        inter = w*h\n",
    "        # IoU = i / (area(a) + area(b) - i)\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter/union  # store result in iou\n",
    "        # keep only elements with an IoU <= overlap\n",
    "        idx = idx[IoU.le(overlap)]\n",
    "    return keep, count\n",
    "\n",
    "def show_nmf(idx, dataset, xBatch, yBatch, is_test, b_bb, b_clas):\n",
    "    ima=dataset.denorm(xBatch)[idx]\n",
    "    if is_test == False:\n",
    "        bbox,clas = get_y(yBatch[0][idx], yBatch[1][idx])\n",
    "    a_ic = actn_to_bb(b_bb[idx], anchors)\n",
    "    clas_pr, clas_ids = b_clas[idx].max(1)\n",
    "    clas_pr = clas_pr.sigmoid()\n",
    "\n",
    "    conf_scores = b_clas[idx].sigmoid().t().data\n",
    "\n",
    "    out1,out2,cc = [],[],[]\n",
    "    for cl in range(0, len(conf_scores)-1):\n",
    "        c_mask = conf_scores[cl] > 0.25\n",
    "        if c_mask.sum() == 0: continue\n",
    "        scores = conf_scores[cl][c_mask]\n",
    "        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n",
    "        boxes = a_ic[l_mask].view(-1, 4)\n",
    "        ids, count = nms(boxes.data, scores, 0.4, 50)\n",
    "        ids = ids[:count]\n",
    "        out1.append(scores[ids])\n",
    "        out2.append(boxes.data[ids])\n",
    "        cc.append([cl]*count)\n",
    "    if not cc:\n",
    "        print(f\"{i}: empty array\")\n",
    "        return\n",
    "    cc = T(np.concatenate(cc))\n",
    "    out1 = torch.cat(out1)\n",
    "    out2 = torch.cat(out2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    torch_gt(ax, ima, out2, cc, out1, 0.1)\n",
    "    \n",
    "\n",
    "####\n",
    "#f_bb: shape == number of anchorboxes * 4; RAW output activations for all bounding boxes for one image \n",
    "#without non maximum suppression\n",
    "#example: [x_upperLeft, y_upperLeft, x_down_right, y_down_right]*number of anchorboxes\n",
    "##\n",
    "#f_clas: shape == number of anchorboxes * number of categories +1(for background);\n",
    "#RAW output acitivations for each of the classes for each anchorbox \n",
    "#example for 3 classes: [prob_class1, probprob_class2, prob_class3]*number of anchorboxes\n",
    "##\n",
    "#thresh: threshold for predicted probability for bbx that should be kept\n",
    "##\n",
    "#input_sz: the size the images get scaled to before beeing put into the neural net\n",
    "##\n",
    "#im_size: the real, original size of the image\n",
    "###\n",
    "#return:\n",
    "#cc: array of category labels for each bounding box\n",
    "##\n",
    "#out1: probabilities/ceranties for predicted category of each bounding box\n",
    "##\n",
    "#out2: array of arrays of bounding box coordinates [x_upperLeft, y_upperLeft, x_down_right, y_down_right]\n",
    "#scaled ot the original size of the image\n",
    "def nms_pred(f_clas, f_bb, anchors, thresh, input_sz, im_size):\n",
    "    a_ic = actn_to_bb(f_bb, anchors)\n",
    "    clas_pr, clas_ids = f_clas.max(1)\n",
    "    clas_pr = clas_pr.sigmoid()\n",
    "\n",
    "    conf_scores = f_clas.sigmoid().t().data\n",
    "\n",
    "    out1,out2,cc = [],[],[]\n",
    "    for cl in range(0, len(conf_scores)-1):\n",
    "        c_mask = conf_scores[cl] > thresh\n",
    "        if c_mask.sum() == 0: continue\n",
    "        scores = conf_scores[cl][c_mask]\n",
    "        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n",
    "        boxes = a_ic[l_mask].view(-1, 4)\n",
    "        ids, count = nms(boxes.data, scores, 0.4, 50)\n",
    "        ids = ids[:count]\n",
    "        out1.append(scores[ids])\n",
    "        out2.append(boxes.data[ids])\n",
    "        cc.append([cl]*count)\n",
    "    if not cc:\n",
    "        return cc, out1, out2\n",
    "    cc = T(np.concatenate(cc))\n",
    "    out1 = torch.cat(out1)\n",
    "    out2 = torch.cat(out2)\n",
    "    cc = to_np(cc)\n",
    "    out1 = to_np(out1)\n",
    "    out2 = to_np(out2)\n",
    "    ##scaling the bbxs to the original size of the image\n",
    "    for i, row in enumerate(out2):\n",
    "        for j, cell in enumerate(row):\n",
    "            out2[i][j] = out2[i][j]*input_sz*(im_size/sz)\n",
    "    return cc, out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MBB_CSV = dp/'tmp/mbb.csv'\n",
    "\n",
    "labs2 = pd.read_csv(dp/'stage_2_train_labels.csv')\n",
    "\n",
    "labs2.x.fillna(0, inplace=True)\n",
    "labs2.y.fillna(0, inplace=True)\n",
    "labs2.width.fillna(1023, inplace=True)\n",
    "labs2.height.fillna(1023, inplace=True)\n",
    "\n",
    "parsed = parse_data(labs2)\n",
    "\n",
    "df_cat_bbxs = pd.DataFrame({'fn': [os.path.basename(parsed[o]['png']) for o in parsed],\n",
    "                   'cat': [parsed[o]['label'] for o in parsed],\n",
    "                   'bbox': [' '.join(str(int(p)) for p in [val for sublist in parsed[o]['boxes'] for val in sublist]) for o in parsed]})\n",
    "\n",
    "df_bbxs = df_cat_bbxs[['fn', 'bbox']]\n",
    "\n",
    "df_bbxs.to_csv(MBB_CSV, index=False)\n",
    "\n",
    "cats = {0: 'normal', 1: 'pneumonia'}\n",
    "mc = []\n",
    "for index, row in tqdm(df_cat_bbxs.iterrows(), total=df_cat_bbxs.shape[0]):\n",
    "    if row['cat']==0:\n",
    "        mc.append([cats[0]])\n",
    "    else:\n",
    "        boxes = np.array([int(i) for i in row['bbox'].split()])\n",
    "        n_o_bbxs = np.array([bb_hw(o) for o in boxes.reshape(-1,4)]).shape[0]\n",
    "        c = []\n",
    "        for i in range(n_o_bbxs):\n",
    "            c.append(cats[1]) \n",
    "        mc.append(c)\n",
    "        \n",
    "id2cat = list(cats.values())\n",
    "cat2id = {v:k for k,v in enumerate(id2cat)}\n",
    "\n",
    "mcs = np.array([np.array([cat2id[p] for p in o]) for o in mc])\n",
    "\n",
    "val_idxs = get_cv_idxs(len(df_bbxs), val_pct=validation_percentage)\n",
    "#val_idxs = []\n",
    "((val_mcs,trn_mcs),) = split_by_idx(val_idxs, mcs)\n",
    "\n",
    "aug_tfms = [RandomRotate(3, p=0.5, tfm_y=TfmType.COORD),\n",
    "            RandomLighting(0.05, 0.05, tfm_y=TfmType.COORD),\n",
    "            RandomFlip(tfm_y=TfmType.COORD)]\n",
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=aug_tfms)\n",
    "md_mbb_csv = ImageClassifierData.from_csv(dp, \n",
    "                                          os.path.basename(PNGS), \n",
    "                                          MBB_CSV, \n",
    "                                          tfms=tfms, \n",
    "                                          bs=bs, \n",
    "                                          continuous=True, \n",
    "                                          num_workers=4,\n",
    "                                          test_name=TEST_TWO,\n",
    "                                          val_idxs=val_idxs)\n",
    "\n",
    "\n",
    "trn_ds2 = ConcatLblDataset(md_mbb_csv.trn_ds, trn_mcs)\n",
    "val_ds2 = ConcatLblDataset(md_mbb_csv.val_ds, val_mcs)\n",
    "md_mbb_csv.trn_dl.dataset = trn_ds2\n",
    "md_mbb_csv.val_dl.dataset = val_ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anc_grids = [4,2,1]\n",
    "# anc_grids = [2]\n",
    "anc_zooms = [0.7, 1., 1.3]\n",
    "# anc_zooms = [1.]\n",
    "anc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]\n",
    "# anc_ratios = [(1.,1.)]\n",
    "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
    "k = len(anchor_scales)\n",
    "anc_offsets = [1/(o*2) for o in anc_grids]\n",
    "\n",
    "anc_x = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_y = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)\n",
    "\n",
    "anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids])\n",
    "grid_sizes = V(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n",
    "anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head_reg4 = SSD_MultiHead(k = k, bias=-4., drop=0.4)\n",
    "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
    "learn = ConvLearner(md_mbb_csv, models)\n",
    "learn.opt_fn = optim.Adam\n",
    "learn.crit = ssd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lrs = np.array([lr/100,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000,1.)\n",
    "learn.sched.plot(n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3*1.2\n",
    "lrs = np.array([lr/10,lr,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#learn.fit(lrs, n_cycle = 2, cycle_len=10, use_clr=(20,10)) #drop4.1\n",
    "learn.fit(lrs, n_cycle = 1, cycle_len=20, use_clr=(30,20))\n",
    "\n",
    "learn.save('fl0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "#learn.fit(lrs/4, n_cycle = 1, cycle_len=10, use_clr=(20,10)) #drop4.1\n",
    "learn.fit(lrs/4, n_cycle = 1, cycle_len=15, use_clr=(40,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('drop4.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## New dataset object without augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aug_tfms_pred = []\n",
    "tfms_pred = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, aug_tfms=aug_tfms_pred)\n",
    "md_mbb_csv_pred = ImageClassifierData.from_csv(dp, \n",
    "                                          os.path.basename(PNGS), \n",
    "                                          MBB_CSV, \n",
    "                                          tfms=tfms_pred, \n",
    "                                          bs=bs, \n",
    "                                          continuous=True, \n",
    "                                          num_workers=4,\n",
    "                                          test_name=TEST_TWO)\n",
    "\n",
    "trn_ds2_pred = ConcatLblDataset(md_mbb_csv_pred.trn_ds, trn_mcs)\n",
    "val_ds2_pred = ConcatLblDataset(md_mbb_csv_pred.val_ds, val_mcs)\n",
    "md_mbb_csv_pred.trn_dl.dataset = trn_ds2_pred\n",
    "md_mbb_csv_pred.val_dl.dataset = val_ds2_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Dummy test set targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test_paths = glob(os.path.join(dp/TEST_TWO, '*.png'))\n",
    "#test_mcs = np.empty(len(test_paths), dtype=object)\n",
    "#for i in range(len(test_paths)):\n",
    "    #test_mcs[i] = np.zeros(1, dtype=int)\n",
    "\n",
    "#test_mcs[0:10]\n",
    "\n",
    "test_ds_placeholder_target = (np.zeros(4, dtype=np.float32), np.zeros(1, dtype=np.int))\n",
    "\n",
    "\n",
    "\n",
    "test_ds_pred = ConcatLblDataset_TestData(md_mbb_csv_pred.test_ds, test_ds_placeholder_target)\n",
    "md_mbb_csv_pred.test_dl.dataset = test_ds_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## New learner object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b8d24c2ecd01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhead_reg4_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSD_MultiHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvnetBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_reg4_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_mbb_csv_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearn_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearn_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssd_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "head_reg4_pred = SSD_MultiHead(k, -4.)\n",
    "models_pred = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4_pred)\n",
    "learn_pred = ConvLearner(md_mbb_csv_pred, models_pred)\n",
    "learn_pred.opt_fn = optim.Adam\n",
    "learn_pred.crit = ssd_loss\n",
    "\n",
    "learn_pred.load('')\n",
    "\n",
    "learn_pred.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###  Check if the order in dataset.fnames is the same as in the batches generated by the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#n=0\n",
    "#for b in iter(md_mbb_csv_pred.test_dl):\n",
    "#    print(n)\n",
    "#    xT, yT = b\n",
    "#    batchT = learn_pred.model(V(xT))\n",
    "#    b_clasT,b_bbT = batchT\n",
    "#    xT = to_np(xT)\n",
    "#    for i in range(4):\n",
    "#        ü = bs*n+i\n",
    "#        print(f'{ü}:{i}')\n",
    "#        show_img(open_image(dp/md_mbb_csv_pred.test_ds.ds.fnames[ü]))\n",
    "#        show_nmf(idx=i, \n",
    "#                 dataset=md_mbb_csv_pred.test_ds.ds, \n",
    "#                 xBatch=xT, \n",
    "#                 yBatch=yT, \n",
    "#                 is_test=True, \n",
    "#                 b_bb=b_bbT, \n",
    "#                 b_clas=b_clasT)\n",
    "#    n = n+1\n",
    "#    if n >=2:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get a dictionary where key==filename and value is a tuple (class_propabilities for each bb, coordinates for each bb), NO NMS or similar, just raw output activations from the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "dict_fname_to_activations = {}\n",
    "for b in iter(md_mbb_csv_pred.test_dl):\n",
    "    print(n)\n",
    "    xT, yT = b\n",
    "    b_clasT,b_bbT = learn_pred.model(V(xT))\n",
    "    for i, (c, bb) in enumerate(zip(b_clasT,b_bbT)):\n",
    "        fn = md_mbb_csv_pred.test_ds.ds.fnames[bs*n+i]\n",
    "        dict_fname_to_activations.update({fn:(c,bb)})\n",
    "    n = n+1\n",
    "\n",
    "len(dict_fname_to_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#dict with bbx coordinates after nms and in format [confidence x_upper_left y_upper_left width height]\n",
    "dict_fname_to_preds_nms_hw = {}\n",
    "for key, value in dict_fname_to_activations.items():\n",
    "    c, b = dict_fname_to_activations[key]\n",
    "    cc, out1, out2 = nms_pred(c, b, anchors, 0.25, sz, original_image_size)\n",
    "    v=[]\n",
    "    for n, cat in enumerate(cc):\n",
    "        if cat == 0:\n",
    "            continue\n",
    "        else:\n",
    "            #xyhw = ''.join(str(np.rint(bb_hw(out2[n])))).replace(\".\", \"\")\n",
    "            xyhw = ''.join(str(np.rint(bb_hw(out2[n].clip(min=0))))).replace(\".\", \"\")\n",
    "            conf = str(out1[n])\n",
    "            concat = ' '.join((conf, xyhw)).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            v.append(concat)\n",
    "    v = ' '.join(v)\n",
    "    k = os.path.splitext(os.path.basename(key))[0]\n",
    "    dict_fname_to_preds_nms_hw.update({k:v})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(dict_fname_to_preds_nms_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(list(dict_fname_to_preds_nms_hw.items()), columns=['patientId', 'PredictionString'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sub_name = f'stage2-drop4.1-NoNegatives-thresh0.25-{str(datetime.datetime.now())}.csv'\n",
    "submission_df.to_csv(SUBMISSIONS/sub_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c rsna-pneumonia-detection-challenge -f SUBMISSIONS/sub_name -m \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "428.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
