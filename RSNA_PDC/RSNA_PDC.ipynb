{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../fastai/old/') #fastai version 0.7\n",
    "#sys.path.append('../../fastai/') #fastai version 1\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "import torchvision.models as pytorch_models\n",
    "\n",
    "import pdb\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from matplotlib.patches import Rectangle\n",
    "import png\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = Path('../../datasets/RSNA_PDC/')\n",
    "\n",
    "DICOMS = dp/'stage_2_train_images'\n",
    "\n",
    "PNGS = dp/'train2_png'\n",
    "PNGS.mkdir(exist_ok=True)\n",
    "\n",
    "#TEST_ONE = 'test1_png'\n",
    "TEST_ONE = 'BLÖDSINN DAMITS AUFFÄLLT'\n",
    "TEST_TWO = 'test2_png'\n",
    "\n",
    "SUBMISSIONS = dp/'submissions'\n",
    "SUBMISSIONS.mkdir(exist_ok=True)\n",
    "\n",
    "#f_model=resnet34\n",
    "f_model = pytorch_models.inception_v3(pretrained=True)\n",
    "\n",
    "sz=1024\n",
    "bs=32\n",
    "\n",
    "validation_percentage = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    ax.get_yaxis().set_visible(True)\n",
    "    return ax\n",
    "\n",
    "def from_dicom_to_png(dicom_path, png_path):\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "    shape = ds.pixel_array.shape\n",
    "    # Convert to float to avoid overflow or underflow losses.\n",
    "    image_2d = ds.pixel_array.astype(float)\n",
    "    # Rescaling grey scale between 0-255\n",
    "    image_2d_scaled = (np.maximum(image_2d,0) / image_2d.max()) * 255.0\n",
    "    # Convert to uint\n",
    "    image_2d_scaled = np.uint8(image_2d_scaled)\n",
    "    # Write the PNG file\n",
    "    with open(png_path, 'wb') as png_file:\n",
    "        w = png.Writer(shape[1], shape[0], greyscale=True)\n",
    "        w.write(png_file, image_2d_scaled)\n",
    "        \n",
    "        \n",
    "def hw_bb(row): return np.array([row['y'], row['x'], row['height']+row['y'], row['width']+row['x']])\n",
    "\n",
    "##[x_upper_left, y_upper_left, width, height]\n",
    "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])\n",
    "\n",
    "def parse_data(df):\n",
    "    \"\"\"\n",
    "    Method to read a CSV file (Pandas dataframe) and parse the \n",
    "    data into the following nested dictionary:\n",
    "\n",
    "      parsed = {\n",
    "        \n",
    "        'patientId-00': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        },\n",
    "        'patientId-01': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        }, ...\n",
    "\n",
    "      }\n",
    "\n",
    "    \"\"\"\n",
    "    parsed = collections.defaultdict(lambda:{'dicom': None,\n",
    "                                        'png': None,     \n",
    "                                        'label': None,\n",
    "                                        'boxes': []})\n",
    "    for n, row in df.iterrows():\n",
    "        # --- Initialize patient entry into parsed \n",
    "        pid = row['patientId']\n",
    "        parsed[pid]['dicom'] = str(DICOMS/f'{pid}.dcm')\n",
    "        parsed[pid]['png'] = str(PNGS/f'{pid}.png')\n",
    "        parsed[pid]['label'] = row['Target']\n",
    "        parsed[pid]['boxes'].append(hw_bb(row))\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def get_lrg(b):\n",
    "    if not b: raise Exception()\n",
    "    b = sorted(b, key=lambda x: np.product(x[-2:]-x[:2]), reverse=True)\n",
    "    return [b[0]]\n",
    "\n",
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    #ax.get_xaxis().set_visible(False)\n",
    "    #ax.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def draw_rect(ax, b, col='white'):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=col, lw=2))\n",
    "    draw_outline(patch, 4)\n",
    "    \n",
    "def draw_text(ax, xy, txt, sz=14, col='white'):\n",
    "    text = ax.text(*xy, txt,\n",
    "        verticalalignment='top', color=col, fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)\n",
    "    \n",
    "def draw_im(im, ann, ax=None):\n",
    "    ax = show_img(im, figsize=(12,6), ax=ax)\n",
    "    l = cats[ann['label']]\n",
    "    for b in ann['boxes']:\n",
    "        b = bb_hw(b)\n",
    "        draw_rect(ax, b)\n",
    "        draw_text(ax, b[:2], l, sz=16)\n",
    "        \n",
    "def draw_idx(im_a, ax=None):\n",
    "    dcm_data = pydicom.read_file(im_a['dicom'])\n",
    "    im = dcm_data.pixel_array\n",
    "    draw_im(im, im_a, ax=ax)\n",
    "    \n",
    "def from_dicom_to_png(parsed):\n",
    "    for k, v in parsed.items():\n",
    "        dcm_data = pydicom.read_file(v['dicom'])\n",
    "        im = dcm_data.pixel_array\n",
    "        imageio.imwrite(v['png'], im)\n",
    "        \n",
    "class ObjDetDataset(Dataset):\n",
    "    def __init__(self, ds, y2): \n",
    "        self.ds = ds \n",
    "        self.y2 = y2\n",
    "    \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.ds[i]\n",
    "        return (x, (y, self.y2[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(dp.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1_dci, s1_ssub, s1_tls, images = ['stage_2_detailed_class_info.csv', 'stage_2_sample_submission.csv', 'stage_2_train_labels.csv', 'stage_2_train_images']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Detailed class info csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dci_df = pd.read_csv(dp/s1_dci)\n",
    "print(dci_df.shape[0])\n",
    "dci_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dci_df.groupby('class').size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Bounding boxes csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bbox_df = pd.read_csv(dp/s1_tls)\n",
    "bbox_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bbox_df.groupby('Target').size().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Combine boxes and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comb_bbox_df = pd.concat([bbox_df, \n",
    "                        dci_df.drop('patientId',1)], 1)\n",
    "print(comb_bbox_df.shape[0], 'combined cases')\n",
    "comb_bbox_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Distribution of boxes per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "box_df = comb_bbox_df.groupby('patientId')['x'].count().reset_index(name='boxes')\n",
    "box_df\n",
    "comb_box_df = pd.merge(comb_bbox_df, box_df, on='patientId')\n",
    "box_df.groupby('boxes').size().reset_index(name='patients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Relation of class and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comb_bbox_df.groupby(['class', 'Target']).size().reset_index(name='Patient Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Image ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_df = pd.DataFrame({'path' : glob(os.path.join(dp/images, '*.dcm'))})\n",
    "image_df['patientId'] = image_df['path'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(image_df.shape[0], 'images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_pat_ids = set(image_df['patientId'])\n",
    "box_pat_ids = set(comb_box_df['patientId'])\n",
    "# check to make sure there is no funny business\n",
    "assert img_pat_ids.union(box_pat_ids)==img_pat_ids, \"Patient IDs should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### DICOM headers and full final dataframe with all information about an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DCM_TAG_LIST = ['PatientAge', 'BodyPartExamined', 'ViewPosition', 'PatientSex']\n",
    "def get_tags(in_path):\n",
    "    c_dicom = pydicom.read_file(in_path, stop_before_pixels=True)\n",
    "    tag_dict = {c_tag: getattr(c_dicom, c_tag, '') \n",
    "         for c_tag in DCM_TAG_LIST}\n",
    "    tag_dict['path'] = in_path\n",
    "    return pd.Series(tag_dict)\n",
    "image_meta_df = image_df.apply(lambda x: get_tags(x['path']), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show the summary\n",
    "image_meta_df['PatientAge'] = image_meta_df['PatientAge'].map(int)\n",
    "image_meta_df['PatientAge'].hist()\n",
    "image_meta_df.drop('path',1).describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_full_df = pd.merge(image_df,\n",
    "                         image_meta_df,\n",
    "                         on='path')\n",
    "image_bbox_df = pd.merge(comb_box_df, \n",
    "                         image_full_df, \n",
    "                         on='patientId',\n",
    "                        how='left')\n",
    "print(image_bbox_df.shape[0], 'image bounding boxes')\n",
    "image_bbox_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create Sample Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_df = image_bbox_df.\\\n",
    "    groupby(['Target','class', 'boxes']).\\\n",
    "    apply(lambda x: x[x['patientId']==x.sample(1)['patientId'].values[0]]).\\\n",
    "    reset_index(drop=True)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Show the position and bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 3, figsize = (20, 10))\n",
    "for c_ax, (c_path, c_rows) in zip(m_axs.flatten(),\n",
    "                    sample_df.groupby(['path'])):\n",
    "    c_dicom = pydicom.read_file(c_path)\n",
    "    c_ax.imshow(c_dicom.pixel_array, cmap='bone')\n",
    "    c_ax.set_title('{class}'.format(**c_rows.iloc[0,:]))\n",
    "    for i, (_, c_row) in enumerate(c_rows.dropna().iterrows()):\n",
    "        c_ax.plot(c_row['x'], c_row['y'], 's', label='{class}'.format(**c_row))\n",
    "        c_ax.add_patch(Rectangle(xy=(c_row['x'], c_row['y']),\n",
    "                                width=c_row['width'],\n",
    "                                height=c_row['height'], \n",
    "                                 alpha = 0.5))\n",
    "        if i==0: c_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Bounding Box Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pos_bbox = image_bbox_df.query('Target==1')\n",
    "pos_bbox.plot.scatter(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax1.set_xlim(0, 1024)\n",
    "ax1.set_ylim(0, 1024)\n",
    "for _, c_row in pos_bbox.sample(1000).iterrows():\n",
    "    ax1.add_patch(Rectangle(xy=(c_row['x'], c_row['y']),\n",
    "                 width=c_row['width'],\n",
    "                 height=c_row['height'],\n",
    "                           alpha=5e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Show the boxes as segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Show the boxes themselves\n",
    "X_STEPS, Y_STEPS = 1024, 1024\n",
    "xx, yy = np.meshgrid(np.linspace(0, 1024, X_STEPS),\n",
    "           np.linspace(0, 1024, Y_STEPS), \n",
    "           indexing='xy')\n",
    "prob_image = np.zeros_like(xx)\n",
    "for _, c_row in pos_bbox.sample(5000).iterrows():\n",
    "    c_mask = (xx>=c_row['x']) & (xx<=(c_row['x']+c_row['width']))\n",
    "    c_mask &= (yy>=c_row['y']) & (yy<=c_row['y']+c_row['height'])\n",
    "    prob_image += c_mask\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax1.imshow(prob_image, cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Overlay the Probability on a few images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 3, figsize = (20, 10))\n",
    "for c_ax, (c_path, c_rows) in zip(m_axs.flatten(),\n",
    "                    sample_df.groupby(['path'])):\n",
    "    c_img_arr = pydicom.read_file(c_path).pixel_array\n",
    "    # overlay\n",
    "    c_img = plt.cm.gray(c_img_arr)\n",
    "    c_img += 0.25*plt.cm.hot(prob_image/prob_image.max())\n",
    "    c_img = np.clip(c_img, 0, 1)\n",
    "    c_ax.imshow(c_img)\n",
    "    \n",
    "    c_ax.set_title('{class}'.format(**c_rows.iloc[0,:]))\n",
    "    for i, (_, c_row) in enumerate(c_rows.dropna().iterrows()):\n",
    "        c_ax.plot(c_row['x'], c_row['y'], 's', label='{class}'.format(**c_row))\n",
    "        c_ax.add_patch(Rectangle(xy=(c_row['x'], c_row['y']),\n",
    "                                width=c_row['width'],\n",
    "                                height=c_row['height'], \n",
    "                                 alpha = 0.5,\n",
    "                                fill=False))\n",
    "        if i==0: c_ax.legend()\n",
    "#fig.savefig('overview.png', figdpi = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save the preprocessed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_bbox_df.to_csv(dp/'image_bbox_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Classifier opacity, no opacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Add new coloumn: opacity/no opacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_bbox_df = pd.read_csv(dp/'image_bbox_full.csv')\n",
    "image_bbox_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets = image_bbox_df['Target']\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classes = []\n",
    "for n, t in tqdm(enumerate(targets), total=len(targets)):\n",
    "    if t == 0:\n",
    "        classes.append('no_opacity')\n",
    "    else:\n",
    "        classes.append('opacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_bbox_df['opacity/no opacity'] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_bbox_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Convert .dcm to .png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add coloumn with paths for .png images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_bbox_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "patientIds = image_bbox_df['patientId']\n",
    "png_paths = []\n",
    "for i in patientIds:\n",
    "    n = i+'.png'\n",
    "    png_paths.append(PNGS/n)\n",
    "\n",
    "image_bbox_df['png_path'] = png_paths\n",
    "image_bbox_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create a distinct list of patient ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_bbox_df_distinct = image_bbox_df.drop_duplicates(subset='path', keep='first')\n",
    "image_bbox_df_distinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Save/read dfs as/from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_bbox_full_csv_name = 'image_bbox_full.csv'\n",
    "image_bbox_distinct_full_csv_name = 'image_bbox_distinct_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_bbox_df.to_csv(dp/image_bbox_full_csv_name, index=False)\n",
    "image_bbox_df_distinct.to_csv(dp/image_bbox_distinct_full_csv_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_bbox_df = pd.read_csv(dp/image_bbox_full_csv_name)\n",
    "image_bbox_df_distinct = pd.read_csv(dp/image_bbox_distinct_full_csv_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for index, row in tqdm(image_bbox_df_distinct.iterrows(), total=image_bbox_df_distinct.shape[0]):\n",
    "    if not os.path.isfile(row['png_path']):\n",
    "        from_dicom_to_png(row['path'], row['png_path'])\n",
    "\n",
    "len(list(PNGS.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img = open_image(image_bbox_df_distinct['png_path'][0])\n",
    "show_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fn': image_bbox_df_distinct['patientId']+'.png', 'cat' : image_bbox_df['opacity/no opacity']})\n",
    "df = df.dropna()\n",
    "df = df.reset_index()\n",
    "df = df.drop(df.columns[[0]], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(dp/'tmp').mkdir(exist_ok=True)\n",
    "CSV = dp/'tmp/class.csv'\n",
    "df.to_csv(CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, crop_type=CropType.NO)\n",
    "md = ImageClassifierData.from_csv(dp, os.path.basename(PNGS), CSV, tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(f_model, md, metrics=[accuracy])\n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.get_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrf=learn.lr_find(1e-5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrs = np.array([lr/1000,lr/100,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrf=learn.lr_find(lrs/10000)\n",
    "learn.sched.plot(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs/5, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs/5, 1, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('opacity-no_opacity-classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('opacity-no_opacity-classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "probs = F.softmax(predict_batch(learn.model, x), -1)\n",
    "x,preds = to_np(x),to_np(probs)\n",
    "preds = np.argmax(preds, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_np = to_np(y)\n",
    "y_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ima=md.val_ds.denorm(x)[i]\n",
    "    b = md.classes[preds[i]]\n",
    "    ax = show_img(ima, ax=ax)\n",
    "    draw_text(ax, (0,0), f'pred:{b}, targ: {y_np[i]}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Largest pneumonia focus detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## dataframe and csv preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labs = pd.read_csv(dp/'stage_1_train_labels.csv')\n",
    "labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labs.x.fillna(0, inplace=True)\n",
    "labs.y.fillna(0, inplace=True)\n",
    "labs.width.fillna(1023, inplace=True)\n",
    "labs.height.fillna(1023, inplace=True)\n",
    "\n",
    "labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parsed = parse_data(labs)\n",
    "\n",
    "parsed_lrg = {a: {'dicom': b['dicom'],\n",
    "                  'png': b['png'],\n",
    "                  'label': b['label'],\n",
    "                  'boxes': get_lrg(b['boxes'])} for a, b in parsed.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cats = {0: 'normal', 1: 'pneumonia'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "patient = '3b081d12-6804-4a33-85cd-712a886e4e01'\n",
    "parsed[patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "parsed_lrg[patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bb = parsed_lrg[patient]['boxes'][0]\n",
    "bb_transformed = bb_hw(bb)\n",
    "bb_original = labs.loc[labs.patientId == patient,:].iloc[1]\n",
    "\n",
    "print(f'Top-Left-Bottom-Right BB: {bb}')\n",
    "print(f'Transformed Top-Left-WH: {bb_transformed}')\n",
    "print(f'Original Top-Left-WH: [{bb_original.x} {bb_original.y} {bb_original.width} {bb_original.height}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    patient = labs.patientId.sample().values[0]\n",
    "    draw_idx(parsed_lrg[patient], ax=ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "(dp/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "CSV = dp/'tmp/class.csv'\n",
    "BB_CSV = dp/'tmp/bb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_lrg = pd.DataFrame({'fn': [parsed_lrg[o]['png'] for o in parsed_lrg],\n",
    "                   'cat': [parsed_lrg[o]['label'] for o in parsed_lrg],\n",
    "                   'bbox': [' '.join(str(p) for p in parsed_lrg[o]['boxes'][0]) for o in parsed_lrg]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_lrg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_lrg.cat.sum()/df_lrg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "li = [str(el) for el in list((PNGS).iterdir())]\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = df_lrg.loc[df_lrg.fn.isin(li),:]\n",
    "dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filePaths = dfs['fn']\n",
    "fns = []\n",
    "for f in filePaths:\n",
    "    fns.append(os.path.basename(f))\n",
    "    \n",
    "dfs['fn'] = fns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs.cat.sum()/dfs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs[['fn', 'bbox']].to_csv(BB_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs[['fn', 'bbox']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Largest opacity detection modeling pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Figuring out input dimension of custom head to stack on top of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cl_df = pd.read_csv(CSV)\n",
    "cl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, crop_type=CropType.NO)\n",
    "md = ImageClassifierData.from_csv(dp, os.path.basename(PNGS), CSV, tfms=tfms, bs=bs)\n",
    "learn = ConvLearner.pretrained(f_model, md, metrics=[accuracy])\n",
    "learn.opt_fn = optim.Adam\n",
    "\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The output dimension of the last Conv Block (BasicBlock-122) is [-1, 512, 16, 16].\n",
    "We will make use of the very handy head concept within the fast.ai library \n",
    "which allows to truncate the pre-trained network to its last conv layer and stack a custom model on top.\n",
    "The input shape of the custom head will be 512 * 16 * 16 = 131072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_to_top_model = 512 * 16 * 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Combinig boxes and classes in one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_idxs = get_cv_idxs(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "augs = [RandomFlip(tfm_y=TfmType.COORD),\n",
    "        RandomRotate(30, tfm_y=TfmType.COORD),\n",
    "        RandomLighting(0.1,0.1, tfm_y=TfmType.COORD)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md_box = ImageClassifierData.from_csv(dp, os.path.basename(PNGS), BB_CSV, tfms=tfms, bs=bs, continuous=True, val_idxs=val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md_class = ImageClassifierData.from_csv(dp, os.path.basename(PNGS), CSV, tfms=tfms_from_model(f_model, sz), bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_ds = ObjDetDataset(md_box.trn_ds, md_class.trn_y)\n",
    "val_ds = ObjDetDataset(md_box.val_ds, md_class.val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "md_box.trn_dl.dataset = trn_ds\n",
    "md_box.val_dl.dataset = val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y=next(iter(md_box.val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx=3\n",
    "ima=md_box.val_ds.ds.denorm(to_np(x))[idx]\n",
    "b = bb_hw(to_np(y[0][idx])) \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = show_img(ima)\n",
    "draw_rect(ax, b)\n",
    "draw_text(ax, b[:2], md_box.classes[y[1][idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Check augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = 4\n",
    "fig,axes = plt.subplots(3,3, figsize=(12,12))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    x, y= next(iter(md_box.aug_dl))\n",
    "    ima = md_box.val_ds.ds.denorm(to_np(x))[idx]\n",
    "    b = bb_hw(to_np(y[idx]))\n",
    "    show_img(ima, ax=ax)\n",
    "    draw_rect(ax, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Custom head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head_reg4 = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(input_to_top_model,256),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(256),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256,4+len(cats)),\n",
    ")\n",
    "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
    "\n",
    "learn = ConvLearner(md_box, models)\n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### How much do we need to multiply the cross_entropy to make it comparable to the f1_loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ratios = []\n",
    "\n",
    "for i in range(200):\n",
    "    x, y = next(iter(md_box.trn_dl))\n",
    "    t = learn.model(V(x))\n",
    "    \n",
    "    bb_t,c_t = y\n",
    "    bb_i,c_i = t[:, :4], t[:, 4:]\n",
    "    bb_i = torch.sigmoid(bb_i)*sz\n",
    "    \n",
    "    reg = F.l1_loss(bb_i, V(bb_t)).data.cpu().numpy()\n",
    "    clas = F.cross_entropy(c_i, V(c_t)).data.cpu().numpy()\n",
    "    \n",
    "    print(reg/clas)\n",
    "    ratios.append(reg/clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.median(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler = int(np.mean(ratios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def detn_loss(input, target):\n",
    "    bb_t,c_t = target\n",
    "    bb_i,c_i = input[:, :4], input[:, 4:]\n",
    "    bb_i = torch.sigmoid(bb_i)*sz\n",
    "    # I looked at these quantities separately first then picked a multiplier\n",
    "    #   to make them approximately equal\n",
    "    return F.l1_loss(bb_i, bb_t) + F.cross_entropy(c_i, c_t)*scaler\n",
    "\n",
    "def detn_l1(input, target):\n",
    "    bb_t,_ = target\n",
    "    bb_i = input[:, :4]\n",
    "    bb_i = torch.sigmoid(bb_i)*sz\n",
    "    return F.l1_loss(V(bb_i),V(bb_t)).data\n",
    "\n",
    "def detn_acc(input, target):\n",
    "    _,c_t = target\n",
    "    c_i = input[:, 4:]\n",
    "    return accuracy(c_i, c_t)\n",
    "\n",
    "learn.crit = detn_loss\n",
    "learn.metrics = [detn_acc, detn_l1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=3, use_clr=(32,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lrs = np.array([lr/100, lr/10, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs/5, 1, cycle_len=5, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs/10, 1, cycle_len=10, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Looking at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = learn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(low=0, high=(len(md_box.val_ds)-1), size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "names = md_box.val_ds.ds.fnames[idx]\n",
    "true_label = [cats[i] for i in md_box.val_ds.y2[idx]]\n",
    "true_box = md_box.val_ds.ds.y[idx]\n",
    "\n",
    "pred_label = [cats[i] for i in np.argmax(y[idx, 4:], axis=1)]\n",
    "pred_box = (expit(y[idx, :4])*1024).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(4,4, figsize=(16,16))\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    im = imageio.imread(names[i])\n",
    "    ax = show_img(im, ax=ax)\n",
    "    draw_rect(ax, true_box[i])\n",
    "    draw_rect(ax, pred_box[i], col='blue')\n",
    "    draw_text(ax, true_box[i][:2], true_label[i])\n",
    "    draw_text(ax, pred_box[i][:2]+np.array([0,60]), pred_label[i], col='blue')\n",
    "    \n",
    "fig.suptitle('16 Random Validation Images (WHITE = Actual; BLUE = Predicted)', fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple pneumonia focus detector (ssd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_CSV = dp/'tmp/class.csv'\n",
    "MBB_CSV = dp/'tmp/mbb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labs2 = pd.read_csv(dp/'stage_2_train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labs2.x.fillna(0, inplace=True)\n",
    "labs2.y.fillna(0, inplace=True)\n",
    "labs2.width.fillna(1023, inplace=True)\n",
    "labs2.height.fillna(1023, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parse_data(labs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dicom': '../../datasets/RSNA_PDC/stage_2_train_images/0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm',\n",
       " 'png': '../../datasets/RSNA_PDC/train2_png/0004cfab-14fd-4e49-80ba-63a80b6bddd6.png',\n",
       " 'label': 0,\n",
       " 'boxes': [array([   0.,    0., 1023., 1023.])]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient = '0004cfab-14fd-4e49-80ba-63a80b6bddd6'\n",
    "parsed[patient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_bbxs = pd.DataFrame({'fn': [os.path.basename(parsed[o]['png']) for o in parsed],\n",
    "                   'cat': [parsed[o]['label'] for o in parsed],\n",
    "                   'bbox': [' '.join(str(int(p)) for p in [val for sublist in parsed[o]['boxes'] for val in sublist]) for o in parsed]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbxs = df_cat_bbxs[['fn', 'bbox']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bbxs.to_csv(MBB_CSV, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c1676d0ecc452d9749b0e9d1bd81fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=26684), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cats = {0: 'normal', 1: 'pneumonia'}\n",
    "mc = []\n",
    "for index, row in tqdm(df_cat_bbxs.iterrows(), total=df_cat_bbxs.shape[0]):\n",
    "    if row['cat']==0:\n",
    "        mc.append([cats[0]])\n",
    "    else:\n",
    "        boxes = np.array([int(i) for i in row['bbox'].split()])\n",
    "        n_o_bbxs = np.array([bb_hw(o) for o in boxes.reshape(-1,4)]).shape[0]\n",
    "        c = []\n",
    "        for i in range(n_o_bbxs):\n",
    "            c.append(cats[1]) \n",
    "        mc.append(c)\n",
    "        \n",
    "id2cat = list(cats.values())\n",
    "cat2id = {v:k for k,v in enumerate(id2cat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mcs = np.array([np.array([cat2id[p] for p in o]) for o in mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0]), array([0]), array([0]), array([0]), array([1, 1]), array([0]), array([0]), array([1, 1]),\n",
       "       array([0]), array([0])], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = get_cv_idxs(len(df_bbxs), val_pct=validation_percentage)\n",
    "#val_idxs = []\n",
    "((val_mcs,trn_mcs),) = split_by_idx(val_idxs, mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms = [RandomRotate(3, p=0.5, tfm_y=TfmType.COORD),\n",
    "            RandomLighting(0.05, 0.05, tfm_y=TfmType.COORD),\n",
    "            RandomFlip(tfm_y=TfmType.COORD)]\n",
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=aug_tfms)\n",
    "md_mbb_csv = ImageClassifierData.from_csv(dp, \n",
    "                                          os.path.basename(PNGS), \n",
    "                                          MBB_CSV, \n",
    "                                          tfms=tfms, \n",
    "                                          bs=bs, \n",
    "                                          continuous=True, \n",
    "                                          num_workers=4,\n",
    "                                          test_name=TEST_TWO,\n",
    "                                          val_idxs=val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as mcolors\n",
    "from cycler import cycler\n",
    "\n",
    "def get_cmap(N):\n",
    "    color_norm  = mcolors.Normalize(vmin=0, vmax=N-1)\n",
    "    return cmx.ScalarMappable(norm=color_norm, cmap='Set3').to_rgba\n",
    "\n",
    "num_colr = 12\n",
    "cmap = get_cmap(num_colr)\n",
    "colr_list = [cmap(float(x)) for x in range(num_colr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ground_truth(ax, im, bbox, clas=None, prs=None, thresh=0.3):\n",
    "    bb = [bb_hw(o) for o in bbox.reshape(-1,4)]\n",
    "    if prs is None:  prs  = [None]*len(bb)\n",
    "    if clas is None: clas = [None]*len(bb)\n",
    "    ax = show_img(im, ax=ax)\n",
    "    for i,(b,c,pr) in enumerate(zip(bb, clas, prs)):\n",
    "        if((b[2]>0) and (pr is None or pr > thresh)):\n",
    "            draw_rect(ax, b, col=colr_list[i%num_colr])\n",
    "            txt = f'{i}: '\n",
    "            if c is not None: txt += ('bg' if c==len(id2cat) else id2cat[c])\n",
    "            if pr is not None: txt += f' {pr:.2f}'\n",
    "            draw_text(ax, b[:2], txt, col=colr_list[i%num_colr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatLblDataset(Dataset):\n",
    "    def __init__(self, ds, y2):\n",
    "        self.ds,self.y2 = ds,y2\n",
    "        self.sz = ds.sz\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x,y = self.ds[i]\n",
    "        return (x, (y,self.y2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds2 = ConcatLblDataset(md_mbb_csv.trn_ds, trn_mcs)\n",
    "val_ds2 = ConcatLblDataset(md_mbb_csv.val_ds, val_mcs)\n",
    "md_mbb_csv.trn_dl.dataset = trn_ds2\n",
    "md_mbb_csv.val_dl.dataset = val_ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25350"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_mbb_csv.trn_ds.ds.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1334"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_mbb_csv.val_ds.ds.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1334"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y=to_np(next(iter(md_mbb_csv.trn_dl)))\n",
    "#x=md_mbb_csv.trn_ds.ds.denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=to_np(md_mbb_csv.trn_ds[0:12])\n",
    "x=md_mbb_csv.trn_ds.ds.denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    show_ground_truth(ax, x[i], y[0][i], y[1][i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bbox per cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_grid = 4\n",
    "k = 1\n",
    "\n",
    "anc_offset = 1/(anc_grid*2)\n",
    "anc_x = np.repeat(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\n",
    "anc_y = np.tile(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\n",
    "\n",
    "anc_ctrs = np.tile(np.stack([anc_x,anc_y], axis=1), (k,1))\n",
    "anc_sizes = np.array([[1/anc_grid,1/anc_grid] for i in range(anc_grid*anc_grid)])\n",
    "anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sizes = V(np.array([1/anc_grid]), requires_grad=False).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(anc_x, anc_y)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1250, 0.1250, 0.2500, 0.2500],\n",
       "        [0.1250, 0.3750, 0.2500, 0.2500],\n",
       "        [0.1250, 0.6250, 0.2500, 0.2500],\n",
       "        [0.1250, 0.8750, 0.2500, 0.2500],\n",
       "        [0.3750, 0.1250, 0.2500, 0.2500],\n",
       "        [0.3750, 0.3750, 0.2500, 0.2500],\n",
       "        [0.3750, 0.6250, 0.2500, 0.2500],\n",
       "        [0.3750, 0.8750, 0.2500, 0.2500],\n",
       "        [0.6250, 0.1250, 0.2500, 0.2500],\n",
       "        [0.6250, 0.3750, 0.2500, 0.2500],\n",
       "        [0.6250, 0.6250, 0.2500, 0.2500],\n",
       "        [0.6250, 0.8750, 0.2500, 0.2500],\n",
       "        [0.8750, 0.1250, 0.2500, 0.2500],\n",
       "        [0.8750, 0.3750, 0.2500, 0.2500],\n",
       "        [0.8750, 0.6250, 0.2500, 0.2500],\n",
       "        [0.8750, 0.8750, 0.2500, 0.2500]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2, ctr+hw/2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.2500, 0.2500],\n",
       "        [0.0000, 0.2500, 0.2500, 0.5000],\n",
       "        [0.0000, 0.5000, 0.2500, 0.7500],\n",
       "        [0.0000, 0.7500, 0.2500, 1.0000],\n",
       "        [0.2500, 0.0000, 0.5000, 0.2500],\n",
       "        [0.2500, 0.2500, 0.5000, 0.5000],\n",
       "        [0.2500, 0.5000, 0.5000, 0.7500],\n",
       "        [0.2500, 0.7500, 0.5000, 1.0000],\n",
       "        [0.5000, 0.0000, 0.7500, 0.2500],\n",
       "        [0.5000, 0.2500, 0.7500, 0.5000],\n",
       "        [0.5000, 0.5000, 0.7500, 0.7500],\n",
       "        [0.5000, 0.7500, 0.7500, 1.0000],\n",
       "        [0.7500, 0.0000, 1.0000, 0.2500],\n",
       "        [0.7500, 0.2500, 1.0000, 0.5000],\n",
       "        [0.7500, 0.5000, 1.0000, 0.7500],\n",
       "        [0.7500, 0.7500, 1.0000, 1.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])\n",
    "anchor_cnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clas = len(id2cat)+1\n",
    "n_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_act = k*(4+n_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StdConv(nn.Module):\n",
    "    def __init__(self, nin, nout, stride=2, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, x): return self.drop(self.bn(F.relu(self.conv(x))))\n",
    "        \n",
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs,-1,nf//k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, k, nin, bias):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.oconv1 = nn.Conv2d(nin, (len(id2cat)+1)*k, 3, padding=1)\n",
    "        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)\n",
    "        self.oconv1.bias.data.zero_().add_(bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return [flatten_conv(self.oconv1(x), self.k),\n",
    "                flatten_conv(self.oconv2(x), self.k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD_Head(nn.Module):\n",
    "    def __init__(self, k, bias):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.sconv0 = StdConv(512,256, stride=1)\n",
    "        self.sconv1 = StdConv(256,256)\n",
    "        self.sconv2 = StdConv(256,256)\n",
    "        self.out = OutConv(k, 256, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv0(x)       \n",
    "        #x = self.sconv1(x)\n",
    "        x = self.sconv2(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grid) # new adaptive maxpool to set (x.size(2) * x.size(3)) equal to number of anchor boxes\n",
    "        return self.out(x)\n",
    "\n",
    "head_reg4 = SSD_Head(k, -3.)\n",
    "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
    "learn = ConvLearner(md_mbb_csv, models)\n",
    "learn.opt_fn = optim.Adam\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]\n",
    "\n",
    "class BCE_Loss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, pred, targ):\n",
    "        t = one_hot_embedding(targ, self.num_classes+1)\n",
    "        t = V(t[:,:-1].contiguous())#.cpu()\n",
    "        x = pred[:,:-1]\n",
    "        w = self.get_weight(x,t)\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, size_average=False)/self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t): return None\n",
    "\n",
    "loss_f = BCE_Loss(len(id2cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(box_a, box_b):\n",
    "    max_xy = torch.min(box_a[:, None, 2:], box_b[None, :, 2:])\n",
    "    min_xy = torch.max(box_a[:, None, :2], box_b[None, :, :2])\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[:, :, 0] * inter[:, :, 1]\n",
    "\n",
    "def box_sz(b): return ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))\n",
    "\n",
    "def jaccard(box_a, box_b):\n",
    "    inter = intersect(box_a, box_b)\n",
    "    union = box_sz(box_a).unsqueeze(1) + box_sz(box_b).unsqueeze(0) - inter\n",
    "    return inter / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(bbox,clas):\n",
    "    bbox = bbox.view(-1,4)/sz\n",
    "    bb_keep = ((bbox[:,2]-bbox[:,0])>0).nonzero()[:,0]\n",
    "    return bbox[bb_keep],clas[bb_keep]\n",
    "\n",
    "def actn_to_bb(actn, anchors):\n",
    "    actn_bbs = torch.tanh(actn)\n",
    "    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]\n",
    "    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n",
    "    return hw2corners(actn_centers, actn_hw)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def ssd_1_loss(b_c,b_bb,bbox,clas,print_it=False):\n",
    "    bbox,clas = get_y(bbox,clas)\n",
    "    a_ic = actn_to_bb(b_bb, anchors)\n",
    "    overlaps = jaccard(bbox.data, anchor_cnr.data)\n",
    "    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)\n",
    "    gt_clas = clas[gt_idx]\n",
    "    pos = gt_overlap > 0.4\n",
    "    pos_idx = torch.nonzero(pos)[:,0]\n",
    "    gt_clas[1-pos] = len(id2cat)\n",
    "    gt_bbox = bbox[gt_idx]\n",
    "    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "    clas_loss  = loss_f(b_c, gt_clas)\n",
    "    return loc_loss, clas_loss\n",
    "\n",
    "def ssd_loss(pred,targ,print_it=False):\n",
    "    lcs,lls = 0.,0.\n",
    "    for b_c,b_bb,bbox,clas in zip(*pred,*targ):\n",
    "        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,print_it)\n",
    "        lls += loc_loss\n",
    "        lcs += clas_loss\n",
    "    if print_it: print(f'loc: {lls.data[0]}, clas: {lcs.data[0]}')\n",
    "    return lls+lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(md_mbb_csv.val_dl))\n",
    "# x,y = V(x).cpu(),V(y)\n",
    "x,y = V(x),V(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,o in enumerate(y): y[i] = o.cuda()\n",
    "learn.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = learn.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # uncomment to debug on cpu\n",
    "#anchors = anchors.cpu(); grid_sizes = grid_sizes.cpu(); anchor_cnr = anchor_cnr.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_loss(batch, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.crit = ssd_loss\n",
    "lr = 3e-3\n",
    "lrs = np.array([lr/100,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000,1.)\n",
    "learn.sched.plot(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=5, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.load('0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md_mbb_csv.val_dl))\n",
    "x,y = V(x),V(y)\n",
    "learn.model.eval()\n",
    "batch = learn.model(x)\n",
    "b_clas,b_bb = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_clas.size(),b_bb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=7\n",
    "b_clasi = b_clas[idx]\n",
    "b_bboxi = b_bb[idx]\n",
    "ima=md_mbb_csv.val_ds.ds.denorm(to_np(x))[idx]\n",
    "bbox,clas = get_y(y[0][idx], y[1][idx])\n",
    "bbox,clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_gt(ax, ima, bbox, clas, prs=None, thresh=0.4):\n",
    "    return show_ground_truth(ax, ima, to_np((bbox*sz).long()),\n",
    "         to_np(clas), to_np(prs) if prs is not None else None, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "torch_gt(ax, ima, bbox, clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "torch_gt(ax, ima, anchor_cnr, b_clasi.max(1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ic = actn_to_bb(b_bboxi, anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "torch_gt(ax, ima, a_ic, b_clasi.max(1)[1], b_clasi.max(1)[0].sigmoid(), thresh=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = jaccard(bbox.data, anchor_cnr.data)\n",
    "overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_overlap,gt_idx = map_to_ground_truth(overlaps)\n",
    "gt_overlap,gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_clas = clas[gt_idx]; gt_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5\n",
    "pos = gt_overlap > thresh\n",
    "pos_idx = torch.nonzero(pos)[:,0]\n",
    "neg_idx = torch.nonzero(1-pos)[:,0]\n",
    "pos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_clas[1-pos] = len(id2cat)\n",
    "[id2cat[o] if o<len(id2cat) else 'bg' for o in gt_clas.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bbox = bbox[gt_idx]\n",
    "loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "clas_loss  = F.cross_entropy(b_clasi, gt_clas)\n",
    "loc_loss,clas_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "for idx,ax in enumerate(axes.flat):\n",
    "    ima=md_mbb_csv.val_ds.ds.denorm(to_np(x))[idx]\n",
    "    bbox,clas = get_y(y[0][idx], y[1][idx])\n",
    "    ima=md_mbb_csv.val_ds.ds.denorm(to_np(x))[idx]\n",
    "    bbox,clas = get_y(bbox,clas); bbox,clas\n",
    "    a_ic = actn_to_bb(b_bb[idx], anchors)\n",
    "    torch_gt(ax, ima, a_ic, b_clas[idx].max(1)[1], b_clas[idx].max(1)[0].sigmoid(), 0.01)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anc_grids = [4,2,1]\n",
    "# anc_grids = [2]\n",
    "anc_zooms = [0.7, 1., 1.3]\n",
    "# anc_zooms = [1.]\n",
    "anc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]\n",
    "# anc_ratios = [(1.,1.)]\n",
    "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
    "k = len(anchor_scales)\n",
    "anc_offsets = [1/(o*2) for o in anc_grids]\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_x = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_y = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids])\n",
    "grid_sizes = V(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n",
    "anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1250, 0.1250, 0.1750, 0.1750],\n",
       "        [0.1250, 0.1250, 0.1750, 0.0875],\n",
       "        [0.1250, 0.1250, 0.0875, 0.1750],\n",
       "        [0.1250, 0.1250, 0.2500, 0.2500],\n",
       "        [0.1250, 0.1250, 0.2500, 0.1250],\n",
       "        [0.1250, 0.1250, 0.1250, 0.2500],\n",
       "        [0.1250, 0.1250, 0.3250, 0.3250],\n",
       "        [0.1250, 0.1250, 0.3250, 0.1625],\n",
       "        [0.1250, 0.1250, 0.1625, 0.3250],\n",
       "        [0.1250, 0.3750, 0.1750, 0.1750],\n",
       "        [0.1250, 0.3750, 0.1750, 0.0875],\n",
       "        [0.1250, 0.3750, 0.0875, 0.1750],\n",
       "        [0.1250, 0.3750, 0.2500, 0.2500],\n",
       "        [0.1250, 0.3750, 0.2500, 0.1250],\n",
       "        [0.1250, 0.3750, 0.1250, 0.2500],\n",
       "        [0.1250, 0.3750, 0.3250, 0.3250],\n",
       "        [0.1250, 0.3750, 0.3250, 0.1625],\n",
       "        [0.1250, 0.3750, 0.1625, 0.3250],\n",
       "        [0.1250, 0.6250, 0.1750, 0.1750],\n",
       "        [0.1250, 0.6250, 0.1750, 0.0875],\n",
       "        [0.1250, 0.6250, 0.0875, 0.1750],\n",
       "        [0.1250, 0.6250, 0.2500, 0.2500],\n",
       "        [0.1250, 0.6250, 0.2500, 0.1250],\n",
       "        [0.1250, 0.6250, 0.1250, 0.2500],\n",
       "        [0.1250, 0.6250, 0.3250, 0.3250],\n",
       "        [0.1250, 0.6250, 0.3250, 0.1625],\n",
       "        [0.1250, 0.6250, 0.1625, 0.3250],\n",
       "        [0.1250, 0.8750, 0.1750, 0.1750],\n",
       "        [0.1250, 0.8750, 0.1750, 0.0875],\n",
       "        [0.1250, 0.8750, 0.0875, 0.1750],\n",
       "        [0.1250, 0.8750, 0.2500, 0.2500],\n",
       "        [0.1250, 0.8750, 0.2500, 0.1250],\n",
       "        [0.1250, 0.8750, 0.1250, 0.2500],\n",
       "        [0.1250, 0.8750, 0.3250, 0.3250],\n",
       "        [0.1250, 0.8750, 0.3250, 0.1625],\n",
       "        [0.1250, 0.8750, 0.1625, 0.3250],\n",
       "        [0.3750, 0.1250, 0.1750, 0.1750],\n",
       "        [0.3750, 0.1250, 0.1750, 0.0875],\n",
       "        [0.3750, 0.1250, 0.0875, 0.1750],\n",
       "        [0.3750, 0.1250, 0.2500, 0.2500],\n",
       "        [0.3750, 0.1250, 0.2500, 0.1250],\n",
       "        [0.3750, 0.1250, 0.1250, 0.2500],\n",
       "        [0.3750, 0.1250, 0.3250, 0.3250],\n",
       "        [0.3750, 0.1250, 0.3250, 0.1625],\n",
       "        [0.3750, 0.1250, 0.1625, 0.3250],\n",
       "        [0.3750, 0.3750, 0.1750, 0.1750],\n",
       "        [0.3750, 0.3750, 0.1750, 0.0875],\n",
       "        [0.3750, 0.3750, 0.0875, 0.1750],\n",
       "        [0.3750, 0.3750, 0.2500, 0.2500],\n",
       "        [0.3750, 0.3750, 0.2500, 0.1250],\n",
       "        [0.3750, 0.3750, 0.1250, 0.2500],\n",
       "        [0.3750, 0.3750, 0.3250, 0.3250],\n",
       "        [0.3750, 0.3750, 0.3250, 0.1625],\n",
       "        [0.3750, 0.3750, 0.1625, 0.3250],\n",
       "        [0.3750, 0.6250, 0.1750, 0.1750],\n",
       "        [0.3750, 0.6250, 0.1750, 0.0875],\n",
       "        [0.3750, 0.6250, 0.0875, 0.1750],\n",
       "        [0.3750, 0.6250, 0.2500, 0.2500],\n",
       "        [0.3750, 0.6250, 0.2500, 0.1250],\n",
       "        [0.3750, 0.6250, 0.1250, 0.2500],\n",
       "        [0.3750, 0.6250, 0.3250, 0.3250],\n",
       "        [0.3750, 0.6250, 0.3250, 0.1625],\n",
       "        [0.3750, 0.6250, 0.1625, 0.3250],\n",
       "        [0.3750, 0.8750, 0.1750, 0.1750],\n",
       "        [0.3750, 0.8750, 0.1750, 0.0875],\n",
       "        [0.3750, 0.8750, 0.0875, 0.1750],\n",
       "        [0.3750, 0.8750, 0.2500, 0.2500],\n",
       "        [0.3750, 0.8750, 0.2500, 0.1250],\n",
       "        [0.3750, 0.8750, 0.1250, 0.2500],\n",
       "        [0.3750, 0.8750, 0.3250, 0.3250],\n",
       "        [0.3750, 0.8750, 0.3250, 0.1625],\n",
       "        [0.3750, 0.8750, 0.1625, 0.3250],\n",
       "        [0.6250, 0.1250, 0.1750, 0.1750],\n",
       "        [0.6250, 0.1250, 0.1750, 0.0875],\n",
       "        [0.6250, 0.1250, 0.0875, 0.1750],\n",
       "        [0.6250, 0.1250, 0.2500, 0.2500],\n",
       "        [0.6250, 0.1250, 0.2500, 0.1250],\n",
       "        [0.6250, 0.1250, 0.1250, 0.2500],\n",
       "        [0.6250, 0.1250, 0.3250, 0.3250],\n",
       "        [0.6250, 0.1250, 0.3250, 0.1625],\n",
       "        [0.6250, 0.1250, 0.1625, 0.3250],\n",
       "        [0.6250, 0.3750, 0.1750, 0.1750],\n",
       "        [0.6250, 0.3750, 0.1750, 0.0875],\n",
       "        [0.6250, 0.3750, 0.0875, 0.1750],\n",
       "        [0.6250, 0.3750, 0.2500, 0.2500],\n",
       "        [0.6250, 0.3750, 0.2500, 0.1250],\n",
       "        [0.6250, 0.3750, 0.1250, 0.2500],\n",
       "        [0.6250, 0.3750, 0.3250, 0.3250],\n",
       "        [0.6250, 0.3750, 0.3250, 0.1625],\n",
       "        [0.6250, 0.3750, 0.1625, 0.3250],\n",
       "        [0.6250, 0.6250, 0.1750, 0.1750],\n",
       "        [0.6250, 0.6250, 0.1750, 0.0875],\n",
       "        [0.6250, 0.6250, 0.0875, 0.1750],\n",
       "        [0.6250, 0.6250, 0.2500, 0.2500],\n",
       "        [0.6250, 0.6250, 0.2500, 0.1250],\n",
       "        [0.6250, 0.6250, 0.1250, 0.2500],\n",
       "        [0.6250, 0.6250, 0.3250, 0.3250],\n",
       "        [0.6250, 0.6250, 0.3250, 0.1625],\n",
       "        [0.6250, 0.6250, 0.1625, 0.3250],\n",
       "        [0.6250, 0.8750, 0.1750, 0.1750],\n",
       "        [0.6250, 0.8750, 0.1750, 0.0875],\n",
       "        [0.6250, 0.8750, 0.0875, 0.1750],\n",
       "        [0.6250, 0.8750, 0.2500, 0.2500],\n",
       "        [0.6250, 0.8750, 0.2500, 0.1250],\n",
       "        [0.6250, 0.8750, 0.1250, 0.2500],\n",
       "        [0.6250, 0.8750, 0.3250, 0.3250],\n",
       "        [0.6250, 0.8750, 0.3250, 0.1625],\n",
       "        [0.6250, 0.8750, 0.1625, 0.3250],\n",
       "        [0.8750, 0.1250, 0.1750, 0.1750],\n",
       "        [0.8750, 0.1250, 0.1750, 0.0875],\n",
       "        [0.8750, 0.1250, 0.0875, 0.1750],\n",
       "        [0.8750, 0.1250, 0.2500, 0.2500],\n",
       "        [0.8750, 0.1250, 0.2500, 0.1250],\n",
       "        [0.8750, 0.1250, 0.1250, 0.2500],\n",
       "        [0.8750, 0.1250, 0.3250, 0.3250],\n",
       "        [0.8750, 0.1250, 0.3250, 0.1625],\n",
       "        [0.8750, 0.1250, 0.1625, 0.3250],\n",
       "        [0.8750, 0.3750, 0.1750, 0.1750],\n",
       "        [0.8750, 0.3750, 0.1750, 0.0875],\n",
       "        [0.8750, 0.3750, 0.0875, 0.1750],\n",
       "        [0.8750, 0.3750, 0.2500, 0.2500],\n",
       "        [0.8750, 0.3750, 0.2500, 0.1250],\n",
       "        [0.8750, 0.3750, 0.1250, 0.2500],\n",
       "        [0.8750, 0.3750, 0.3250, 0.3250],\n",
       "        [0.8750, 0.3750, 0.3250, 0.1625],\n",
       "        [0.8750, 0.3750, 0.1625, 0.3250],\n",
       "        [0.8750, 0.6250, 0.1750, 0.1750],\n",
       "        [0.8750, 0.6250, 0.1750, 0.0875],\n",
       "        [0.8750, 0.6250, 0.0875, 0.1750],\n",
       "        [0.8750, 0.6250, 0.2500, 0.2500],\n",
       "        [0.8750, 0.6250, 0.2500, 0.1250],\n",
       "        [0.8750, 0.6250, 0.1250, 0.2500],\n",
       "        [0.8750, 0.6250, 0.3250, 0.3250],\n",
       "        [0.8750, 0.6250, 0.3250, 0.1625],\n",
       "        [0.8750, 0.6250, 0.1625, 0.3250],\n",
       "        [0.8750, 0.8750, 0.1750, 0.1750],\n",
       "        [0.8750, 0.8750, 0.1750, 0.0875],\n",
       "        [0.8750, 0.8750, 0.0875, 0.1750],\n",
       "        [0.8750, 0.8750, 0.2500, 0.2500],\n",
       "        [0.8750, 0.8750, 0.2500, 0.1250],\n",
       "        [0.8750, 0.8750, 0.1250, 0.2500],\n",
       "        [0.8750, 0.8750, 0.3250, 0.3250],\n",
       "        [0.8750, 0.8750, 0.3250, 0.1625],\n",
       "        [0.8750, 0.8750, 0.1625, 0.3250],\n",
       "        [0.2500, 0.2500, 0.3500, 0.3500],\n",
       "        [0.2500, 0.2500, 0.3500, 0.1750],\n",
       "        [0.2500, 0.2500, 0.1750, 0.3500],\n",
       "        [0.2500, 0.2500, 0.5000, 0.5000],\n",
       "        [0.2500, 0.2500, 0.5000, 0.2500],\n",
       "        [0.2500, 0.2500, 0.2500, 0.5000],\n",
       "        [0.2500, 0.2500, 0.6500, 0.6500],\n",
       "        [0.2500, 0.2500, 0.6500, 0.3250],\n",
       "        [0.2500, 0.2500, 0.3250, 0.6500],\n",
       "        [0.2500, 0.7500, 0.3500, 0.3500],\n",
       "        [0.2500, 0.7500, 0.3500, 0.1750],\n",
       "        [0.2500, 0.7500, 0.1750, 0.3500],\n",
       "        [0.2500, 0.7500, 0.5000, 0.5000],\n",
       "        [0.2500, 0.7500, 0.5000, 0.2500],\n",
       "        [0.2500, 0.7500, 0.2500, 0.5000],\n",
       "        [0.2500, 0.7500, 0.6500, 0.6500],\n",
       "        [0.2500, 0.7500, 0.6500, 0.3250],\n",
       "        [0.2500, 0.7500, 0.3250, 0.6500],\n",
       "        [0.7500, 0.2500, 0.3500, 0.3500],\n",
       "        [0.7500, 0.2500, 0.3500, 0.1750],\n",
       "        [0.7500, 0.2500, 0.1750, 0.3500],\n",
       "        [0.7500, 0.2500, 0.5000, 0.5000],\n",
       "        [0.7500, 0.2500, 0.5000, 0.2500],\n",
       "        [0.7500, 0.2500, 0.2500, 0.5000],\n",
       "        [0.7500, 0.2500, 0.6500, 0.6500],\n",
       "        [0.7500, 0.2500, 0.6500, 0.3250],\n",
       "        [0.7500, 0.2500, 0.3250, 0.6500],\n",
       "        [0.7500, 0.7500, 0.3500, 0.3500],\n",
       "        [0.7500, 0.7500, 0.3500, 0.1750],\n",
       "        [0.7500, 0.7500, 0.1750, 0.3500],\n",
       "        [0.7500, 0.7500, 0.5000, 0.5000],\n",
       "        [0.7500, 0.7500, 0.5000, 0.2500],\n",
       "        [0.7500, 0.7500, 0.2500, 0.5000],\n",
       "        [0.7500, 0.7500, 0.6500, 0.6500],\n",
       "        [0.7500, 0.7500, 0.6500, 0.3250],\n",
       "        [0.7500, 0.7500, 0.3250, 0.6500],\n",
       "        [0.5000, 0.5000, 0.7000, 0.7000],\n",
       "        [0.5000, 0.5000, 0.7000, 0.3500],\n",
       "        [0.5000, 0.5000, 0.3500, 0.7000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.3000, 1.3000],\n",
       "        [0.5000, 0.5000, 1.3000, 0.6500],\n",
       "        [0.5000, 0.5000, 0.6500, 1.3000]], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=to_np(next(iter(md_mbb_csv.val_dl)))\n",
    "x=md_mbb_csv.val_ds.ds.denorm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.reshape((to_np(anchor_cnr) + to_np(torch.randn(*anchor_cnr.size()))*0.01)*sz, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "show_ground_truth(ax, x[0], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "show_ground_truth(ax, x[0], a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop=0.4\n",
    "\n",
    "class SSD_MultiHead(nn.Module):\n",
    "    def __init__(self, k, bias):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.sconv1 = StdConv(512,256, drop=drop)\n",
    "        self.sconv2 = StdConv(256,256, drop=drop)\n",
    "        self.sconv3 = StdConv(256,256, drop=drop)\n",
    "        self.out0 = OutConv(k, 256, bias)\n",
    "        self.out1 = OutConv(k, 256, bias)\n",
    "        self.out2 = OutConv(k, 256, bias)\n",
    "        self.out3 = OutConv(k, 256, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv1(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[0]) # adaptive maxpool for 1st size of anchors\n",
    "        o1c,o1l = self.out1(x)\n",
    "        x = self.sconv2(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[1]) # adaptive maxpool for 2nd size of anchors\n",
    "        o2c,o2l = self.out2(x) \n",
    "        x = self.sconv3(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[2]) # adaptive maxpool for 3rd size of anchors\n",
    "        o3c,o3l = self.out3(x)\n",
    "#         return [o1c, o1l]\n",
    "        return [torch.cat([o1c,o2c,o3c], dim=1),\n",
    "                torch.cat([o1l,o2l,o3l], dim=1)]\n",
    "\n",
    "head_reg4 = SSD_MultiHead(k, -4.)\n",
    "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
    "learn = ConvLearner(md_mbb_csv, models)\n",
    "learn.opt_fn = optim.Adam\n",
    "learn.crit = ssd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lrs = np.array([lr/100,lr/10,lr])\n",
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md_mbb_csv.val_dl))\n",
    "x,y = V(x),V(y)\n",
    "batch = learn.model(V(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0].size(),batch[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssd_loss(batch, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000,1.)\n",
    "learn.sched.plot(n_skip_end=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, cycle_len=4, use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs/2, 1, cycle_len=4, use_clr=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('prefocal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('prefocal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md_mbb_csv.val_dl))\n",
    "y = V(y)\n",
    "batch = learn.model(V(x))\n",
    "b_clas,b_bb = batch\n",
    "x = to_np(x)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "for idx,ax in enumerate(axes.flat):\n",
    "    ima=md_mbb_csv.val_ds.ds.denorm(x)[idx]\n",
    "    bbox,clas = get_y(y[0][idx], y[1][idx])\n",
    "    a_ic = actn_to_bb(b_bb[idx], anchors)\n",
    "    torch_gt(ax, ima, a_ic, b_clas[idx].max(1)[1], b_clas[idx].max(1)[0].sigmoid(), 0.21)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(thresh):\n",
    "    x,y = next(iter(md_mbb_csv.val_dl))\n",
    "    y = V(y)\n",
    "    batch = learn.model(V(x))\n",
    "    b_clas,b_bb = batch\n",
    "\n",
    "    x = to_np(x)\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    for idx,ax in enumerate(axes.flat):\n",
    "        ima=md_mbb_csv.val_ds.ds.denorm(x)[idx]\n",
    "        bbox,clas = get_y(y[0][idx], y[1][idx])\n",
    "        a_ic = actn_to_bb(b_bb[idx], anchors)\n",
    "        clas_pr, clas_ids = b_clas[idx].max(1)\n",
    "        clas_pr = clas_pr.sigmoid()\n",
    "        torch_gt(ax, ima, a_ic, clas_ids, clas_pr, clas_pr.max().data[0]*thresh)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(BCE_Loss):\n",
    "    def get_weight(self,x,t):\n",
    "        alpha,gamma = 0.25,1\n",
    "        p = x.sigmoid()\n",
    "        pt = p*t + (1-p)*(1-t)\n",
    "        w = alpha*t + (1-alpha)*(1-t)\n",
    "        return w * (1-pt).pow(gamma)\n",
    "\n",
    "loss_f = FocalLoss(len(id2cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md_mbb_csv.trn_dl))\n",
    "x,y = V(x),V(y)\n",
    "batch = learn.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssd_loss(batch, y, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lrs = np.array([lr/100,lr/10,lr])\n",
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000,1.)\n",
    "learn.sched.plot(n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3*1.2\n",
    "lrs = np.array([lr/10,lr/1,lr/0.1])\n",
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(lrs, n_cycle = 4, cycle_len=5, use_clr=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fl0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fl0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs/4, n_cycle = 2, cycle_len=5, use_clr=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('drop4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('drop4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes, scores, overlap=0.5, top_k=100):\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    if boxes.numel() == 0: return keep\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    v, idx = scores.sort(0)  # sort in ascending order\n",
    "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
    "    xx1 = boxes.new()\n",
    "    yy1 = boxes.new()\n",
    "    xx2 = boxes.new()\n",
    "    yy2 = boxes.new()\n",
    "    w = boxes.new()\n",
    "    h = boxes.new()\n",
    "\n",
    "    count = 0\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        if idx.size(0) == 1: break\n",
    "        idx = idx[:-1]  # remove kept element from view\n",
    "        # load bboxes of next highest vals\n",
    "        torch.index_select(x1, 0, idx, out=xx1)\n",
    "        torch.index_select(y1, 0, idx, out=yy1)\n",
    "        torch.index_select(x2, 0, idx, out=xx2)\n",
    "        torch.index_select(y2, 0, idx, out=yy2)\n",
    "        # store element-wise max with next highest score\n",
    "        xx1 = torch.clamp(xx1, min=x1[i])\n",
    "        yy1 = torch.clamp(yy1, min=y1[i])\n",
    "        xx2 = torch.clamp(xx2, max=x2[i])\n",
    "        yy2 = torch.clamp(yy2, max=y2[i])\n",
    "        w.resize_as_(xx2)\n",
    "        h.resize_as_(yy2)\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        # check sizes of xx1 and xx2.. after each iteration\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "        inter = w*h\n",
    "        # IoU = i / (area(a) + area(b) - i)\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter/union  # store result in iou\n",
    "        # keep only elements with an IoU <= overlap\n",
    "        idx = idx[IoU.le(overlap)]\n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md_mbb_csv.val_dl))\n",
    "y = V(y)\n",
    "batch = learn.model(V(x))\n",
    "b_clas,b_bb = batch\n",
    "x = to_np(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_bb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ü = bs-1\n",
    "show_img(md_mbb_csv.val_ds.ds.denorm(x)[ü])\n",
    "show_img(open_image(dp/md_mbb_csv.val_ds.ds.fnames[ü]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_nmf(idx, dataset, xBatch, yBatch, is_test, b_bb, b_clas):\n",
    "    ima=dataset.denorm(xBatch)[idx]\n",
    "    if is_test == False:\n",
    "        bbox,clas = get_y(yBatch[0][idx], yBatch[1][idx])\n",
    "    a_ic = actn_to_bb(b_bb[idx], anchors)\n",
    "    clas_pr, clas_ids = b_clas[idx].max(1)\n",
    "    clas_pr = clas_pr.sigmoid()\n",
    "\n",
    "    conf_scores = b_clas[idx].sigmoid().t().data\n",
    "\n",
    "    out1,out2,cc = [],[],[]\n",
    "    for cl in range(0, len(conf_scores)-1):\n",
    "        c_mask = conf_scores[cl] > 0.25\n",
    "        if c_mask.sum() == 0: continue\n",
    "        scores = conf_scores[cl][c_mask]\n",
    "        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n",
    "        boxes = a_ic[l_mask].view(-1, 4)\n",
    "        ids, count = nms(boxes.data, scores, 0.4, 50)\n",
    "        ids = ids[:count]\n",
    "        out1.append(scores[ids])\n",
    "        out2.append(boxes.data[ids])\n",
    "        cc.append([cl]*count)\n",
    "    if not cc:\n",
    "        print(f\"{i}: empty array\")\n",
    "        return\n",
    "    cc = T(np.concatenate(cc))\n",
    "    out1 = torch.cat(out1)\n",
    "    out2 = torch.cat(out2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    torch_gt(ax, ima, out2, cc, out1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(12): show_nmf(i, md_mbb_csv.val_ds.ds, x, y, False, b_bb, b_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New dataset object without augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms_pred = []\n",
    "tfms_pred = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, aug_tfms=aug_tfms_pred)\n",
    "md_mbb_csv_pred = ImageClassifierData.from_csv(dp, \n",
    "                                          os.path.basename(PNGS), \n",
    "                                          MBB_CSV, \n",
    "                                          tfms=tfms_pred, \n",
    "                                          bs=bs, \n",
    "                                          continuous=True, \n",
    "                                          num_workers=4,\n",
    "                                          test_name=TEST_TWO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds2_pred = ConcatLblDataset(md_mbb_csv_pred.trn_ds, trn_mcs)\n",
    "val_ds2_pred = ConcatLblDataset(md_mbb_csv_pred.val_ds, val_mcs)\n",
    "md_mbb_csv_pred.trn_dl.dataset = trn_ds2_pred\n",
    "md_mbb_csv_pred.val_dl.dataset = val_ds2_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workaround for test dataset \"targets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_paths = glob(os.path.join(dp/TEST_TWO, '*.png'))\n",
    "#test_mcs = np.empty(len(test_paths), dtype=object)\n",
    "#for i in range(len(test_paths)):\n",
    "    #test_mcs[i] = np.zeros(1, dtype=int)\n",
    "\n",
    "#test_mcs[0:10]\n",
    "\n",
    "test_ds_placeholder_target = (np.zeros(4, dtype=np.float32), np.zeros(1, dtype=np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatLblDataset_TestData(Dataset):\n",
    "    def __init__(self, ds, y_tuple_placeholder):\n",
    "        self.ds,self.y = ds,y_tuple_placeholder\n",
    "        self.sz = ds.sz\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x = self.ds.get_x(i)\n",
    "        x = self.ds.transform(x)\n",
    "        return (x, (self.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_pred = ConcatLblDataset_TestData(md_mbb_csv_pred.test_ds, test_ds_placeholder_target)\n",
    "md_mbb_csv_pred.test_dl.dataset = test_ds_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New learner object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_reg4_pred = SSD_MultiHead(k, -4.)\n",
    "models_pred = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4_pred)\n",
    "learn_pred = ConvLearner(md_mbb_csv_pred, models_pred)\n",
    "learn_pred.opt_fn = optim.Adam\n",
    "learn_pred.crit = ssd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_pred.load('drop4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_pred.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Check if the order in dataset.fnames is the same as in the batches generated by the dataloader (IT IS!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "for b in iter(md_mbb_csv_pred.test_dl):\n",
    "    print(n)\n",
    "    xT, yT = b\n",
    "    batchT = learn_pred.model(V(xT))\n",
    "    b_clasT,b_bbT = batch\n",
    "    xT = to_np(xT)\n",
    "    for i in range(2):\n",
    "        print(f'{n}: {i}')\n",
    "        ü = 64*n+i\n",
    "        #show_img(open_image(dp/md_mbb_csv.val_ds.ds.fnames[ü]))\n",
    "        show_img(open_image(dp/md_mbb_csv_pred.test_ds.ds.fnames[ü]))\n",
    "        show_nmf(idx=i, \n",
    "                 dataset=md_mbb_csv_pred.test_ds.ds, \n",
    "                 x=xT, \n",
    "                 y=yT, \n",
    "                 is_test=True, \n",
    "                 b_bb=b_bbT, \n",
    "                 b_clas=b_clasT)\n",
    "    n = n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a dictionary where key==filename and value is a tuple (class_propabilities for each bb, coordinates for each bb), NO NMS or similar, just raw output activations from the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xj, yj = next(iter(md_mbb_csv_pred.test_dl)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b_clasj,b_bbj = learn_pred.model(V(xj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (c, bb) in enumerate(zip(b_clasj,b_bbj)):\n",
    "        #print(c)\n",
    "        #print(bb)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_clasj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b_clasj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_clasj = b_clasj[0]\n",
    "o_bbj = b_bbj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_clasj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_bbj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "dict_fname_to_activations = {}\n",
    "for b in iter(md_mbb_csv_pred.test_dl):\n",
    "    print(n)\n",
    "    xT, yT = b\n",
    "    b_clasT,b_bbT = learn_pred.model(V(xT))\n",
    "    for i, (c, bb) in enumerate(zip(b_clasT,b_bbT)):\n",
    "        fn = md_mbb_csv_pred.test_ds.ds.fnames[bz*n+i]\n",
    "        dict_fname_to_activations.update({fn:(c,bb)})\n",
    "    n = n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "#f_bb: shape == number of anchorboxes * 4; RAW output activations for all bounding boxes for one image \n",
    "#without non maximum suppression\n",
    "#example: [x_upperLeft, y_upperLeft, x_down_right, y_down_right]*number of anchorboxes\n",
    "##\n",
    "#f_clas: shape == number of anchorboxes * number of categories +1(for background);\n",
    "#RAW output acitivations for each of the classes for each anchorbox \n",
    "#example for 3 classes: [prob_class1, probprob_class2, prob_class3]*number of anchorboxes\n",
    "##\n",
    "#thresh: threshold for predicted probability for bbx that should be kept\n",
    "##\n",
    "#input_sz: the size the images get scaled to before beeing put into the neural net\n",
    "##\n",
    "#im_size: the real, original size of the image\n",
    "###\n",
    "#return:\n",
    "#cc: array of category labels for each bounding box\n",
    "##\n",
    "#out1: probabilities/ceranties for predicted category of each bounding box\n",
    "##\n",
    "#out2: array of arrays of bounding box coordinates [x_upperLeft, y_upperLeft, x_down_right, y_down_right]\n",
    "#scaled ot the original size of the image\n",
    "def nms_pred(f_clas, f_bb, anchors, thresh, input_sz, im_size):\n",
    "    a_ic = actn_to_bb(f_bb, anchors)\n",
    "    clas_pr, clas_ids = f_clas.max(1)\n",
    "    clas_pr = clas_pr.sigmoid()\n",
    "\n",
    "    conf_scores = f_clas.sigmoid().t().data\n",
    "\n",
    "    out1,out2,cc = [],[],[]\n",
    "    for cl in range(0, len(conf_scores)-1):\n",
    "        c_mask = conf_scores[cl] > thresh\n",
    "        if c_mask.sum() == 0: continue\n",
    "        scores = conf_scores[cl][c_mask]\n",
    "        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n",
    "        boxes = a_ic[l_mask].view(-1, 4)\n",
    "        ids, count = nms(boxes.data, scores, 0.4, 50)\n",
    "        ids = ids[:count]\n",
    "        out1.append(scores[ids])\n",
    "        out2.append(boxes.data[ids])\n",
    "        cc.append([cl]*count)\n",
    "    if not cc:\n",
    "        return cc, out1, out2\n",
    "    cc = T(np.concatenate(cc))\n",
    "    out1 = torch.cat(out1)\n",
    "    out2 = torch.cat(out2)\n",
    "    cc = to_np(cc)\n",
    "    out1 = to_np(out1)\n",
    "    out2 = to_np(out2)\n",
    "    ##scaling the bbxs to the original size of the image\n",
    "    for i, row in enumerate(out2):\n",
    "        for j, cell in enumerate(row):\n",
    "            out2[i][j] = out2[i][j]*input_sz*(im_size/sz)\n",
    "    return cc, out1, out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz=[\"g\"]\n",
    "not zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_t = md_mbb_csv_pred.test_ds.ds.fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, b = dict_fname_to_activations[fns_t[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc, out1, out2 = nms_pred(c, b, anchors, 0.2, sz, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyhw = ''.join(str(np.rint(bb_hw(out2[0])))).replace(\".\", \"\")\n",
    "xyhw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = str(out1[0])\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join((conf, xyhw)).replace(\"[\", \"\").replace(\"]\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###dict with bbx coordinates after nms and in format [confidence x_upper_left y_upper_left width height]\n",
    "dict_fname_to_preds_nms_hw = {}\n",
    "for key, value in dict_fname_to_activations.items():\n",
    "    c, b = dict_fname_to_activations[key]\n",
    "    cc, out1, out2 = nms_pred(c, b, anchors, 0.2, sz, 1024)\n",
    "    v=[]\n",
    "    for n, cat in enumerate(cc):\n",
    "        if cat == 0:\n",
    "            continue\n",
    "        else:\n",
    "            xyhw = xyhw = ''.join(str(np.rint(bb_hw(out2[n])))).replace(\".\", \"\")\n",
    "            conf = str(out1[n])\n",
    "            concat = ' '.join((conf, xyhw)).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            v.append(concat)\n",
    "    v = ' '.join(v)\n",
    "    k = os.path.splitext(os.path.basename(key))[0]\n",
    "    dict_fname_to_preds_nms_hw.update({k:v})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_fname_to_preds_nms_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(list(dict_fname_to_preds_nms_hw.items()), columns=['patientId', 'PredictionString'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "submission_df.to_csv(SUBMISSIONS/f'stage2-str(datetime.datetime.now())', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "403.767px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 630.85,
   "position": {
    "height": "652.85px",
    "left": "633px",
    "right": "487px",
    "top": "189px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
