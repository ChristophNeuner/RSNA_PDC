{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../fastai/old/') #fastai version 0.7\n",
    "#sys.path.append('../fastai/') #fastai version 1\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "import torchvision.models as pytorch_models\n",
    "\n",
    "import pdb\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from matplotlib.patches import Rectangle\n",
    "import png\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as mcolors\n",
    "from cycler import cycler\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)\n",
    "torch.backends.cudnn.benchmark=True\n",
    "\n",
    "dp = Path('../datasets/RSNA_PDC/')\n",
    "\n",
    "DICOMS = dp/'stage_2_train_images'\n",
    "\n",
    "PNGS = dp/'train2_png'\n",
    "PNGS.mkdir(exist_ok=True)\n",
    "\n",
    "TEST_ONE = 'test1_png'\n",
    "TEST_TWO = 'test2_png'\n",
    "\n",
    "SUBMISSIONS = dp/'submissions'\n",
    "SUBMISSIONS.mkdir(exist_ok=True)\n",
    "\n",
    "f_model=resnet34\n",
    "#f_model = pytorch_models.inception_v3(pretrained=True)\n",
    "\n",
    "sz=512\n",
    "bs=16\n",
    "\n",
    "validation_percentage = 0.05\n",
    "\n",
    "original_image_size = 1024\n",
    "\n",
    "num_colr = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ObjDetDataset(Dataset):\n",
    "    def __init__(self, ds, y2): \n",
    "        self.ds = ds \n",
    "        self.y2 = y2\n",
    "    \n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.ds[i]\n",
    "        return (x, (y, self.y2[i]))\n",
    "\n",
    "\n",
    "class ConcatLblDataset(Dataset):\n",
    "    def __init__(self, ds, y2):\n",
    "        self.ds,self.y2 = ds,y2\n",
    "        self.sz = ds.sz\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x,y = self.ds[i]\n",
    "        return (x, (y,self.y2[i]))\n",
    "\n",
    "class ConcatLblDataset_TestData(Dataset):\n",
    "    def __init__(self, ds, y_tuple_placeholder):\n",
    "        self.ds,self.y = ds,y_tuple_placeholder\n",
    "        self.sz = ds.sz\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x = self.ds.get_x(i)\n",
    "        x = self.ds.transform(x)\n",
    "        return (x, (self.y))\n",
    "    \n",
    "class StdConv(nn.Module):\n",
    "    def __init__(self, nin, nout, stride=2, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(nout)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, x): return self.drop(self.bn(F.relu(self.conv(x))))\n",
    "        \n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, k, nin, bias):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.oconv1 = nn.Conv2d(nin, (len(id2cat)+1)*k, 3, padding=1)\n",
    "        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)\n",
    "        self.oconv1.bias.data.zero_().add_(bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return [flatten_conv(self.oconv1(x), self.k),\n",
    "                flatten_conv(self.oconv2(x), self.k)]\n",
    "\n",
    "\n",
    "class SSD_MultiHead(nn.Module):\n",
    "    def __init__(self, k, bias, drop):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "        self.sconv1 = StdConv(512,256, drop=drop)\n",
    "        self.sconv2 = StdConv(256,256, drop=drop)\n",
    "        self.sconv3 = StdConv(256,256, drop=drop)\n",
    "        self.out0 = OutConv(k, 256, bias)\n",
    "        self.out1 = OutConv(k, 256, bias)\n",
    "        self.out2 = OutConv(k, 256, bias)\n",
    "        self.out3 = OutConv(k, 256, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(x))\n",
    "        x = self.sconv1(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[0]) # adaptive maxpool for 1st size of anchors\n",
    "        o1c,o1l = self.out1(x)\n",
    "        x = self.sconv2(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[1]) # adaptive maxpool for 2nd size of anchors\n",
    "        o2c,o2l = self.out2(x) \n",
    "        x = self.sconv3(x)\n",
    "        x = F.adaptive_max_pool2d(x, anc_grids[2]) # adaptive maxpool for 3rd size of anchors\n",
    "        o3c,o3l = self.out3(x)\n",
    "#         return [o1c, o1l]\n",
    "        return [torch.cat([o1c,o2c,o3c], dim=1),\n",
    "                torch.cat([o1l,o2l,o3l], dim=1)]\n",
    "\n",
    "\n",
    "class BCE_Loss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, pred, targ):\n",
    "        t = one_hot_embedding(targ, self.num_classes+1)\n",
    "        t = V(t[:,:-1].contiguous())#.cpu()\n",
    "        x = pred[:,:-1]\n",
    "        w = self.get_weight(x,t)\n",
    "        #return F.binary_cross_entropy_with_logits(x, t, w, size_average=False)/self.num_classes\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, reduction='sum')/self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t): return None\n",
    "\n",
    "\n",
    "class FocalLoss(BCE_Loss):\n",
    "    def get_weight(self,x,t):\n",
    "        alpha,gamma = 0.25,1\n",
    "        p = x.sigmoid()\n",
    "        pt = p*t + (1-p)*(1-t)\n",
    "        w = alpha*t + (1-alpha)*(1-t)\n",
    "        return w * (1-pt).pow(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(True)\n",
    "    ax.get_yaxis().set_visible(True)\n",
    "    return ax\n",
    "\n",
    "def from_dicom_to_png(dicom_path, png_path):\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "    shape = ds.pixel_array.shape\n",
    "    # Convert to float to avoid overflow or underflow losses.\n",
    "    image_2d = ds.pixel_array.astype(float)\n",
    "    # Rescaling grey scale between 0-255\n",
    "    image_2d_scaled = (np.maximum(image_2d,0) / image_2d.max()) * 255.0\n",
    "    # Convert to uint\n",
    "    image_2d_scaled = np.uint8(image_2d_scaled)\n",
    "    # Write the PNG file\n",
    "    with open(png_path, 'wb') as png_file:\n",
    "        w = png.Writer(shape[1], shape[0], greyscale=True)\n",
    "        w.write(png_file, image_2d_scaled)\n",
    "        \n",
    "        \n",
    "def hw_bb(row): return np.array([row['y'], row['x'], row['height']+row['y'], row['width']+row['x']])\n",
    "\n",
    "##[x_upper_left, y_upper_left, width, height]\n",
    "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])\n",
    "\n",
    "def parse_data(df):\n",
    "    \"\"\"\n",
    "    Method to read a CSV file (Pandas dataframe) and parse the \n",
    "    data into the following nested dictionary:\n",
    "\n",
    "      parsed = {\n",
    "        \n",
    "        'patientId-00': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        },\n",
    "        'patientId-01': {\n",
    "            'dicom': path/to/dicom/file,\n",
    "            'label': either 0 or 1 for normal or pnuemonia, \n",
    "            'boxes': list of box(es)\n",
    "        }, ...\n",
    "\n",
    "      }\n",
    "\n",
    "    \"\"\"\n",
    "    parsed = collections.defaultdict(lambda:{'dicom': None,\n",
    "                                        'png': None,     \n",
    "                                        'label': None,\n",
    "                                        'boxes': []})\n",
    "    for n, row in df.iterrows():\n",
    "        # --- Initialize patient entry into parsed \n",
    "        pid = row['patientId']\n",
    "        parsed[pid]['dicom'] = str(DICOMS/f'{pid}.dcm')\n",
    "        parsed[pid]['png'] = str(PNGS/f'{pid}.png')\n",
    "        parsed[pid]['label'] = row['Target']\n",
    "        parsed[pid]['boxes'].append(hw_bb(row))\n",
    "\n",
    "    return parsed\n",
    "\n",
    "def get_lrg(b):\n",
    "    if not b: raise Exception()\n",
    "    b = sorted(b, key=lambda x: np.product(x[-2:]-x[:2]), reverse=True)\n",
    "    return [b[0]]\n",
    "\n",
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    #ax.get_xaxis().set_visible(False)\n",
    "    #ax.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def draw_rect(ax, b, col='white'):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=col, lw=2))\n",
    "    draw_outline(patch, 4)\n",
    "    \n",
    "def draw_text(ax, xy, txt, sz=14, col='white'):\n",
    "    text = ax.text(*xy, txt,\n",
    "        verticalalignment='top', color=col, fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)\n",
    "    \n",
    "def draw_im(im, ann, ax=None):\n",
    "    ax = show_img(im, figsize=(12,6), ax=ax)\n",
    "    l = cats[ann['label']]\n",
    "    for b in ann['boxes']:\n",
    "        b = bb_hw(b)\n",
    "        draw_rect(ax, b)\n",
    "        draw_text(ax, b[:2], l, sz=16)\n",
    "        \n",
    "def draw_idx(im_a, ax=None):\n",
    "    dcm_data = pydicom.read_file(im_a['dicom'])\n",
    "    im = dcm_data.pixel_array\n",
    "    draw_im(im, im_a, ax=ax)\n",
    "    \n",
    "def from_dicom_to_png(parsed):\n",
    "    for k, v in parsed.items():\n",
    "        dcm_data = pydicom.read_file(v['dicom'])\n",
    "        im = dcm_data.pixel_array\n",
    "        imageio.imwrite(v['png'], im)\n",
    "\n",
    "\n",
    "\n",
    "def show_ground_truth(ax, im, bbox, clas=None, prs=None, thresh=0.3):\n",
    "    bb = [bb_hw(o) for o in bbox.reshape(-1,4)]\n",
    "    if prs is None:  prs  = [None]*len(bb)\n",
    "    if clas is None: clas = [None]*len(bb)\n",
    "    ax = show_img(im, ax=ax)\n",
    "    for i,(b,c,pr) in enumerate(zip(bb, clas, prs)):\n",
    "        if((b[2]>0) and (pr is None or pr > thresh)):\n",
    "            draw_rect(ax, b, col=colr_list[i%num_colr])\n",
    "            txt = f'{i}: '\n",
    "            if c is not None: txt += ('bg' if c==len(id2cat) else id2cat[c])\n",
    "            if pr is not None: txt += f' {pr:.2f}'\n",
    "            draw_text(ax, b[:2], txt, col=colr_list[i%num_colr])\n",
    "\n",
    "\n",
    "def get_cmap(N):\n",
    "    color_norm  = mcolors.Normalize(vmin=0, vmax=N-1)\n",
    "    return cmx.ScalarMappable(norm=color_norm, cmap='Set3').to_rgba\n",
    "            \n",
    "cmap = get_cmap(num_colr)\n",
    "colr_list = [cmap(float(x)) for x in range(num_colr)]\n",
    "            \n",
    "\n",
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2, ctr+hw/2], dim=1)\n",
    "\n",
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs,-1,nf//k)\n",
    "\n",
    "    \n",
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]\n",
    "\n",
    "\n",
    "def intersect(box_a, box_b):\n",
    "    max_xy = torch.min(box_a[:, None, 2:], box_b[None, :, 2:])\n",
    "    min_xy = torch.max(box_a[:, None, :2], box_b[None, :, :2])\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[:, :, 0] * inter[:, :, 1]\n",
    "\n",
    "def box_sz(b): return ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))\n",
    "\n",
    "def jaccard(box_a, box_b):\n",
    "    inter = intersect(box_a, box_b)\n",
    "    union = box_sz(box_a).unsqueeze(1) + box_sz(box_b).unsqueeze(0) - inter\n",
    "    return inter / union\n",
    "\n",
    "def get_y(bbox,clas):\n",
    "    bbox = bbox.view(-1,4)/sz\n",
    "    bb_keep = ((bbox[:,2]-bbox[:,0])>0).nonzero()[:,0]\n",
    "    return bbox[bb_keep],clas[bb_keep]\n",
    "\n",
    "def actn_to_bb(actn, anchors):\n",
    "    actn_bbs = torch.tanh(actn)\n",
    "    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]\n",
    "    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n",
    "    return hw2corners(actn_centers, actn_hw)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx\n",
    "\n",
    "def ssd_1_loss(b_c, b_bb, bbox, clas, print_it=False):\n",
    "    bbox,clas = get_y(bbox,clas)\n",
    "    a_ic = actn_to_bb(b_bb, anchors)\n",
    "    overlaps = jaccard(bbox.data, anchor_cnr.data)\n",
    "    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)\n",
    "    gt_clas = clas[gt_idx]\n",
    "    pos = gt_overlap > 0.4\n",
    "    pos_idx = torch.nonzero(pos)[:,0]\n",
    "    gt_clas[1-pos] = len(id2cat)\n",
    "    gt_bbox = bbox[gt_idx]\n",
    "    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "    clas_loss  = loss_f(b_c, gt_clas)\n",
    "    return loc_loss, clas_loss\n",
    "\n",
    "def ssd_loss(pred,targ, print_it=False):\n",
    "    lcs,lls = 0.,0.\n",
    "    for b_c,b_bb,bbox,clas in zip(*pred,*targ):\n",
    "        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,loss_function,print_it)\n",
    "        lls += loc_loss\n",
    "        lcs += clas_loss\n",
    "    if print_it: print(f'loc: {lls.data[0]}, clas: {lcs.data[0]}')\n",
    "    return lls+lcs\n",
    "\n",
    "def torch_gt(ax, ima, bbox, clas, prs=None, thresh=0.4):\n",
    "    return show_ground_truth(ax, ima, to_np((bbox*sz).long()),\n",
    "         to_np(clas), to_np(prs) if prs is not None else None, thresh)\n",
    "\n",
    "def plot_results(thresh):\n",
    "    x,y = next(iter(md_mbb_csv.val_dl))\n",
    "    y = V(y)\n",
    "    batch = learn.model(V(x))\n",
    "    b_clas,b_bb = batch\n",
    "\n",
    "    x = to_np(x)\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "    for idx,ax in enumerate(axes.flat):\n",
    "        ima=md_mbb_csv.val_ds.ds.denorm(x)[idx]\n",
    "        bbox,clas = get_y(y[0][idx], y[1][idx])\n",
    "        a_ic = actn_to_bb(b_bb[idx], anchors)\n",
    "        clas_pr, clas_ids = b_clas[idx].max(1)\n",
    "        clas_pr = clas_pr.sigmoid()\n",
    "        torch_gt(ax, ima, a_ic, clas_ids, clas_pr, clas_pr.max().data[0]*thresh)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "###non max suppression\n",
    "def nms(boxes, scores, overlap=0.5, top_k=100):\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    if boxes.numel() == 0: return keep\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    area = torch.mul(x2 - x1, y2 - y1)\n",
    "    v, idx = scores.sort(0)  # sort in ascending order\n",
    "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
    "    xx1 = boxes.new()\n",
    "    yy1 = boxes.new()\n",
    "    xx2 = boxes.new()\n",
    "    yy2 = boxes.new()\n",
    "    w = boxes.new()\n",
    "    h = boxes.new()\n",
    "\n",
    "    count = 0\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # index of current largest val\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        if idx.size(0) == 1: break\n",
    "        idx = idx[:-1]  # remove kept element from view\n",
    "        # load bboxes of next highest vals\n",
    "        torch.index_select(x1, 0, idx, out=xx1)\n",
    "        torch.index_select(y1, 0, idx, out=yy1)\n",
    "        torch.index_select(x2, 0, idx, out=xx2)\n",
    "        torch.index_select(y2, 0, idx, out=yy2)\n",
    "        # store element-wise max with next highest score\n",
    "        xx1 = torch.clamp(xx1, min=x1[i])\n",
    "        yy1 = torch.clamp(yy1, min=y1[i])\n",
    "        xx2 = torch.clamp(xx2, max=x2[i])\n",
    "        yy2 = torch.clamp(yy2, max=y2[i])\n",
    "        w.resize_as_(xx2)\n",
    "        h.resize_as_(yy2)\n",
    "        w = xx2 - xx1\n",
    "        h = yy2 - yy1\n",
    "        # check sizes of xx1 and xx2.. after each iteration\n",
    "        w = torch.clamp(w, min=0.0)\n",
    "        h = torch.clamp(h, min=0.0)\n",
    "        inter = w*h\n",
    "        # IoU = i / (area(a) + area(b) - i)\n",
    "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
    "        union = (rem_areas - inter) + area[i]\n",
    "        IoU = inter/union  # store result in iou\n",
    "        # keep only elements with an IoU <= overlap\n",
    "        idx = idx[IoU.le(overlap)]\n",
    "    return keep, count\n",
    "\n",
    "def show_nmf(idx, dataset, xBatch, yBatch, is_test, b_bb, b_clas):\n",
    "    ima=dataset.denorm(xBatch)[idx]\n",
    "    if is_test == False:\n",
    "        bbox,clas = get_y(yBatch[0][idx], yBatch[1][idx])\n",
    "    a_ic = actn_to_bb(b_bb[idx], anchors)\n",
    "    clas_pr, clas_ids = b_clas[idx].max(1)\n",
    "    clas_pr = clas_pr.sigmoid()\n",
    "\n",
    "    conf_scores = b_clas[idx].sigmoid().t().data\n",
    "\n",
    "    out1,out2,cc = [],[],[]\n",
    "    for cl in range(0, len(conf_scores)-1):\n",
    "        c_mask = conf_scores[cl] > 0.25\n",
    "        if c_mask.sum() == 0: continue\n",
    "        scores = conf_scores[cl][c_mask]\n",
    "        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n",
    "        boxes = a_ic[l_mask].view(-1, 4)\n",
    "        ids, count = nms(boxes.data, scores, 0.4, 50)\n",
    "        ids = ids[:count]\n",
    "        out1.append(scores[ids])\n",
    "        out2.append(boxes.data[ids])\n",
    "        cc.append([cl]*count)\n",
    "    if not cc:\n",
    "        print(f\"{i}: empty array\")\n",
    "        return\n",
    "    cc = T(np.concatenate(cc))\n",
    "    out1 = torch.cat(out1)\n",
    "    out2 = torch.cat(out2)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    torch_gt(ax, ima, out2, cc, out1, 0.1)\n",
    "    \n",
    "\n",
    "####\n",
    "#f_bb: shape == number of anchorboxes * 4; RAW output activations for all bounding boxes for one image \n",
    "#without non maximum suppression\n",
    "#example: [x_upperLeft, y_upperLeft, x_down_right, y_down_right]*number of anchorboxes\n",
    "##\n",
    "#f_clas: shape == number of anchorboxes * number of categories +1(for background);\n",
    "#RAW output acitivations for each of the classes for each anchorbox \n",
    "#example for 3 classes: [prob_class1, probprob_class2, prob_class3]*number of anchorboxes\n",
    "##\n",
    "#thresh: threshold for predicted probability for bbx that should be kept\n",
    "##\n",
    "#input_sz: the size the images get scaled to before beeing put into the neural net\n",
    "##\n",
    "#im_size: the real, original size of the image\n",
    "###\n",
    "#return:\n",
    "#cc: array of category labels for each bounding box\n",
    "##\n",
    "#out1: probabilities/ceranties for predicted category of each bounding box\n",
    "##\n",
    "#out2: array of arrays of bounding box coordinates [x_upperLeft, y_upperLeft, x_down_right, y_down_right]\n",
    "#scaled ot the original size of the image\n",
    "def nms_pred(f_clas, f_bb, anchors, thresh, input_sz, im_size):\n",
    "    a_ic = actn_to_bb(f_bb, anchors)\n",
    "    clas_pr, clas_ids = f_clas.max(1)\n",
    "    clas_pr = clas_pr.sigmoid()\n",
    "\n",
    "    conf_scores = f_clas.sigmoid().t().data\n",
    "\n",
    "    out1,out2,cc = [],[],[]\n",
    "    for cl in range(0, len(conf_scores)-1):\n",
    "        c_mask = conf_scores[cl] > thresh\n",
    "        if c_mask.sum() == 0: continue\n",
    "        scores = conf_scores[cl][c_mask]\n",
    "        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n",
    "        boxes = a_ic[l_mask].view(-1, 4)\n",
    "        ids, count = nms(boxes.data, scores, 0.4, 50)\n",
    "        ids = ids[:count]\n",
    "        out1.append(scores[ids])\n",
    "        out2.append(boxes.data[ids])\n",
    "        cc.append([cl]*count)\n",
    "    if not cc:\n",
    "        return cc, out1, out2\n",
    "    cc = T(np.concatenate(cc))\n",
    "    out1 = torch.cat(out1)\n",
    "    out2 = torch.cat(out2)\n",
    "    cc = to_np(cc)\n",
    "    out1 = to_np(out1)\n",
    "    out2 = to_np(out2)\n",
    "    ##scaling the bbxs to the original size of the image\n",
    "    for i, row in enumerate(out2):\n",
    "        for j, cell in enumerate(row):\n",
    "            out2[i][j] = out2[i][j]*input_sz*(im_size/sz)\n",
    "    return cc, out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MBB_CSV = dp/'tmp/mbb.csv'\n",
    "\n",
    "labs2 = pd.read_csv(dp/'stage_2_train_labels.csv')\n",
    "\n",
    "labs2.x.fillna(0, inplace=True)\n",
    "labs2.y.fillna(0, inplace=True)\n",
    "labs2.width.fillna(1023, inplace=True)\n",
    "labs2.height.fillna(1023, inplace=True)\n",
    "\n",
    "parsed = parse_data(labs2)\n",
    "\n",
    "df_cat_bbxs = pd.DataFrame({'fn': [os.path.basename(parsed[o]['png']) for o in parsed],\n",
    "                   'cat': [parsed[o]['label'] for o in parsed],\n",
    "                   'bbox': [' '.join(str(int(p)) for p in [val for sublist in parsed[o]['boxes'] for val in sublist]) for o in parsed]})\n",
    "\n",
    "df_bbxs = df_cat_bbxs[['fn', 'bbox']]\n",
    "\n",
    "df_bbxs.to_csv(MBB_CSV, index=False)\n",
    "\n",
    "cats = {0: 'normal', 1: 'pneumonia'}\n",
    "mc = []\n",
    "for index, row in tqdm(df_cat_bbxs.iterrows(), total=df_cat_bbxs.shape[0]):\n",
    "    if row['cat']==0:\n",
    "        mc.append([cats[0]])\n",
    "    else:\n",
    "        boxes = np.array([int(i) for i in row['bbox'].split()])\n",
    "        n_o_bbxs = np.array([bb_hw(o) for o in boxes.reshape(-1,4)]).shape[0]\n",
    "        c = []\n",
    "        for i in range(n_o_bbxs):\n",
    "            c.append(cats[1]) \n",
    "        mc.append(c)\n",
    "        \n",
    "id2cat = list(cats.values())\n",
    "cat2id = {v:k for k,v in enumerate(id2cat)}\n",
    "\n",
    "mcs = np.array([np.array([cat2id[p] for p in o]) for o in mc])\n",
    "\n",
    "val_idxs = get_cv_idxs(len(df_bbxs), val_pct=validation_percentage)\n",
    "#val_idxs = []\n",
    "((val_mcs,trn_mcs),) = split_by_idx(val_idxs, mcs)\n",
    "\n",
    "aug_tfms = [RandomRotate(3, p=0.5, tfm_y=TfmType.COORD),\n",
    "            RandomLighting(0.05, 0.05, tfm_y=TfmType.COORD),\n",
    "            RandomFlip(tfm_y=TfmType.COORD)]\n",
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=aug_tfms)\n",
    "md_mbb_csv = ImageClassifierData.from_csv(dp, \n",
    "                                          os.path.basename(PNGS), \n",
    "                                          MBB_CSV, \n",
    "                                          tfms=tfms, \n",
    "                                          bs=bs, \n",
    "                                          continuous=True, \n",
    "                                          num_workers=4,\n",
    "                                          test_name=TEST_TWO,\n",
    "                                          val_idxs=val_idxs)\n",
    "\n",
    "\n",
    "trn_ds2 = ConcatLblDataset(md_mbb_csv.trn_ds, trn_mcs)\n",
    "val_ds2 = ConcatLblDataset(md_mbb_csv.val_ds, val_mcs)\n",
    "md_mbb_csv.trn_dl.dataset = trn_ds2\n",
    "md_mbb_csv.val_dl.dataset = val_ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anc_grids = [4,2,1]\n",
    "# anc_grids = [2]\n",
    "anc_zooms = [0.7, 1., 1.3]\n",
    "# anc_zooms = [1.]\n",
    "anc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]\n",
    "# anc_ratios = [(1.,1.)]\n",
    "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
    "k = len(anchor_scales)\n",
    "anc_offsets = [1/(o*2) for o in anc_grids]\n",
    "\n",
    "anc_x = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_y = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)\n",
    "\n",
    "anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids])\n",
    "grid_sizes = V(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n",
    "anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "head_reg4 = SSD_MultiHead(k = k, bias=-4., drop=0.4)\n",
    "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
    "learn = ConvLearner(md_mbb_csv, models)\n",
    "learn.opt_fn = optim.Adam\n",
    "learn.crit = ssd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lrs = np.array([lr/100,lr/10,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000,1.)\n",
    "learn.sched.plot(n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-3*1.2\n",
    "lrs = np.array([lr/10,lr,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#learn.fit(lrs, n_cycle = 2, cycle_len=10, use_clr=(20,10)) #drop4.1\n",
    "learn.fit(lrs, n_cycle = 1, cycle_len=20, use_clr=(30,20))\n",
    "\n",
    "learn.save('fl0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "#learn.fit(lrs/4, n_cycle = 1, cycle_len=10, use_clr=(20,10)) #drop4.1\n",
    "learn.fit(lrs/4, n_cycle = 1, cycle_len=15, use_clr=(40,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('drop4.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New dataset object without augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_tfms_pred = []\n",
    "tfms_pred = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.NO, aug_tfms=aug_tfms_pred)\n",
    "md_mbb_csv_pred = ImageClassifierData.from_csv(dp, \n",
    "                                          os.path.basename(PNGS), \n",
    "                                          MBB_CSV, \n",
    "                                          tfms=tfms_pred, \n",
    "                                          bs=bs, \n",
    "                                          continuous=True, \n",
    "                                          num_workers=4,\n",
    "                                          test_name=TEST_TWO)\n",
    "\n",
    "trn_ds2_pred = ConcatLblDataset(md_mbb_csv_pred.trn_ds, trn_mcs)\n",
    "val_ds2_pred = ConcatLblDataset(md_mbb_csv_pred.val_ds, val_mcs)\n",
    "md_mbb_csv_pred.trn_dl.dataset = trn_ds2_pred\n",
    "md_mbb_csv_pred.val_dl.dataset = val_ds2_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy test set targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_paths = glob(os.path.join(dp/TEST_TWO, '*.png'))\n",
    "#test_mcs = np.empty(len(test_paths), dtype=object)\n",
    "#for i in range(len(test_paths)):\n",
    "    #test_mcs[i] = np.zeros(1, dtype=int)\n",
    "\n",
    "#test_mcs[0:10]\n",
    "\n",
    "test_ds_placeholder_target = (np.zeros(4, dtype=np.float32), np.zeros(1, dtype=np.int))\n",
    "\n",
    "\n",
    "\n",
    "test_ds_pred = ConcatLblDataset_TestData(md_mbb_csv_pred.test_ds, test_ds_placeholder_target)\n",
    "md_mbb_csv_pred.test_dl.dataset = test_ds_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New learner object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b8d24c2ecd01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhead_reg4_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSD_MultiHead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodels_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvnetBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_reg4_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlearn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_mbb_csv_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlearn_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearn_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssd_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "head_reg4_pred = SSD_MultiHead(k, -4.)\n",
    "models_pred = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4_pred)\n",
    "learn_pred = ConvLearner(md_mbb_csv_pred, models_pred)\n",
    "learn_pred.opt_fn = optim.Adam\n",
    "learn_pred.crit = ssd_loss\n",
    "\n",
    "learn_pred.load('')\n",
    "\n",
    "learn_pred.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check if the order in dataset.fnames is the same as in the batches generated by the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n=0\n",
    "#for b in iter(md_mbb_csv_pred.test_dl):\n",
    "#    print(n)\n",
    "#    xT, yT = b\n",
    "#    batchT = learn_pred.model(V(xT))\n",
    "#    b_clasT,b_bbT = batchT\n",
    "#    xT = to_np(xT)\n",
    "#    for i in range(4):\n",
    "#        ü = bs*n+i\n",
    "#        print(f'{ü}:{i}')\n",
    "#        show_img(open_image(dp/md_mbb_csv_pred.test_ds.ds.fnames[ü]))\n",
    "#        show_nmf(idx=i, \n",
    "#                 dataset=md_mbb_csv_pred.test_ds.ds, \n",
    "#                 xBatch=xT, \n",
    "#                 yBatch=yT, \n",
    "#                 is_test=True, \n",
    "#                 b_bb=b_bbT, \n",
    "#                 b_clas=b_clasT)\n",
    "#    n = n+1\n",
    "#    if n >=2:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a dictionary where key==filename and value is a tuple (class_propabilities for each bb, coordinates for each bb), NO NMS or similar, just raw output activations from the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "dict_fname_to_activations = {}\n",
    "for b in iter(md_mbb_csv_pred.test_dl):\n",
    "    print(n)\n",
    "    xT, yT = b\n",
    "    b_clasT,b_bbT = learn_pred.model(V(xT))\n",
    "    for i, (c, bb) in enumerate(zip(b_clasT,b_bbT)):\n",
    "        fn = md_mbb_csv_pred.test_ds.ds.fnames[bs*n+i]\n",
    "        dict_fname_to_activations.update({fn:(c,bb)})\n",
    "    n = n+1\n",
    "\n",
    "len(dict_fname_to_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict with bbx coordinates after nms and in format [confidence x_upper_left y_upper_left width height]\n",
    "dict_fname_to_preds_nms_hw = {}\n",
    "for key, value in dict_fname_to_activations.items():\n",
    "    c, b = dict_fname_to_activations[key]\n",
    "    cc, out1, out2 = nms_pred(c, b, anchors, 0.25, sz, original_image_size)\n",
    "    v=[]\n",
    "    for n, cat in enumerate(cc):\n",
    "        if cat == 0:\n",
    "            continue\n",
    "        else:\n",
    "            #xyhw = ''.join(str(np.rint(bb_hw(out2[n])))).replace(\".\", \"\")\n",
    "            xyhw = ''.join(str(np.rint(bb_hw(out2[n].clip(min=0))))).replace(\".\", \"\")\n",
    "            conf = str(out1[n])\n",
    "            concat = ' '.join((conf, xyhw)).replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "            v.append(concat)\n",
    "    v = ' '.join(v)\n",
    "    k = os.path.splitext(os.path.basename(key))[0]\n",
    "    dict_fname_to_preds_nms_hw.update({k:v})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_fname_to_preds_nms_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(list(dict_fname_to_preds_nms_hw.items()), columns=['patientId', 'PredictionString'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_name = f'stage2-drop4.1-NoNegatives-thresh0.25-{str(datetime.datetime.now())}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(SUBMISSIONS/sub_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Order submission file ids like the sample-submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../datasets/RSNA_PDC/submissions/stage2-drop4.2-NoNegatives-2018-10-28 09:28:50.545534.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/submissions/2018-10-24 15:44:05.577908'),\n",
       " PosixPath('../datasets/RSNA_PDC/submissions/stage2-drop4.2-withNegatives-2018-10-28 08:57:48.421195.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/submissions/stage2-drop4.2-NoNegatives-2018-10-28 09:25:34.462274.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/submissions/.ipynb_checkpoints')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(SUBMISSIONS.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../datasets/RSNA_PDC/image_bbox_full.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/test1_png'),\n",
       " PosixPath('../datasets/RSNA_PDC/models'),\n",
       " PosixPath('../datasets/RSNA_PDC/image_bbox_distinct_full.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_2_detailed_class_info.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_1_test_images'),\n",
       " PosixPath('../datasets/RSNA_PDC/submissions'),\n",
       " PosixPath('../datasets/RSNA_PDC/test2_png'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_1_detailed_class_info.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_1_sample_submission.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_2_train_labels.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_2_train_images'),\n",
       " PosixPath('../datasets/RSNA_PDC/tmp'),\n",
       " PosixPath('../datasets/RSNA_PDC/GCP Credits Request Link - RSNA.txt'),\n",
       " PosixPath('../datasets/RSNA_PDC/.ipynb_checkpoints'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_2_sample_submission.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/train2_png'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_1_train_images'),\n",
       " PosixPath('../datasets/RSNA_PDC/train_png'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_1_train_labels.csv'),\n",
       " PosixPath('../datasets/RSNA_PDC/stage_2_test_images')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dp.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_submission2_df = pd.read_csv(dp/'stage_2_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000a175-0e68-4ca4-b1af-167204a7e0bc</td>\n",
       "      <td>0.5 0 0 100 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005d3cc-3c3f-40b9-93c3-46231c3eb813</td>\n",
       "      <td>0.5 0 0 100 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000686d7-f4fc-448d-97a0-44fa9c5d3aa6</td>\n",
       "      <td>0.5 0 0 100 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e3a7d-c0ca-4349-bb26-5af2d8993c3d</td>\n",
       "      <td>0.5 0 0 100 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00100a24-854d-423d-a092-edcf6179e061</td>\n",
       "      <td>0.5 0 0 100 100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId PredictionString\n",
       "0  0000a175-0e68-4ca4-b1af-167204a7e0bc  0.5 0 0 100 100\n",
       "1  0005d3cc-3c3f-40b9-93c3-46231c3eb813  0.5 0 0 100 100\n",
       "2  000686d7-f4fc-448d-97a0-44fa9c5d3aa6  0.5 0 0 100 100\n",
       "3  000e3a7d-c0ca-4349-bb26-5af2d8993c3d  0.5 0 0 100 100\n",
       "4  00100a24-854d-423d-a092-edcf6179e061  0.5 0 0 100 100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(SUBMISSIONS/'stage2-drop4.2-NoNegatives-2018-10-28 09:25:34.462274.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1378f79c-6ea0-41e9-98a9-1b15c2c54a7d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27e74851-45bb-46f7-8412-defe6d91f4fb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13060344-a70e-478a-8754-378e72ba00c3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2b0bfba4-ae3c-41a8-9e21-c3053b896445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27d281c6-ee2b-4ca3-b5a0-96622436b397</td>\n",
       "      <td>0.99937195   0   0 103 180 0.95054185   22    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>255f3ba9-89bc-4ce4-840d-43267635124e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2ff95f9e-bada-492a-8e17-ccec1781b9e7</td>\n",
       "      <td>0.49112582   0  21 460 991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21f097aa-37d0-4340-a132-85e80880f5d0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0d5eccb8-befa-400a-b2ec-3bfee6004787</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2ff6f390-1e4c-489e-91ac-6b18448a08db</td>\n",
       "      <td>0.26053515 270 542 213 246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1d01a9c3-e3fc-48f2-b78d-6c82223d40be</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2bacaba5-1a0e-44f9-b654-c384aa466ea8</td>\n",
       "      <td>0.53055733 149 352 281 496 0.42007858 620 281 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>048a68fe-87f7-44a2-953d-d00651cc2605</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3129f567-c659-42f8-b4e1-8a5e3827b477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>117061eb-6454-4f19-8730-95c65a4029bb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13e0c176-e18b-435a-983b-f81e763837e6</td>\n",
       "      <td>0.9999367 448 384 129 257 0.26660335 934 890 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1a3e7d64-adbc-4c49-abbe-3f871f3c557a</td>\n",
       "      <td>0.377284 214 345 304 493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11df5b6f-d134-4195-9cc0-6273e4be67c5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1b157958-b600-4aa7-98d6-f711a333d3f7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24f7c131-9d07-4251-83fc-20ab9079e326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               patientId  \\\n",
       "0   1378f79c-6ea0-41e9-98a9-1b15c2c54a7d   \n",
       "1   27e74851-45bb-46f7-8412-defe6d91f4fb   \n",
       "2   13060344-a70e-478a-8754-378e72ba00c3   \n",
       "3   2b0bfba4-ae3c-41a8-9e21-c3053b896445   \n",
       "4   27d281c6-ee2b-4ca3-b5a0-96622436b397   \n",
       "5   255f3ba9-89bc-4ce4-840d-43267635124e   \n",
       "6   2ff95f9e-bada-492a-8e17-ccec1781b9e7   \n",
       "7   21f097aa-37d0-4340-a132-85e80880f5d0   \n",
       "8   0d5eccb8-befa-400a-b2ec-3bfee6004787   \n",
       "9   2ff6f390-1e4c-489e-91ac-6b18448a08db   \n",
       "10  1d01a9c3-e3fc-48f2-b78d-6c82223d40be   \n",
       "11  2bacaba5-1a0e-44f9-b654-c384aa466ea8   \n",
       "12  048a68fe-87f7-44a2-953d-d00651cc2605   \n",
       "13  3129f567-c659-42f8-b4e1-8a5e3827b477   \n",
       "14  117061eb-6454-4f19-8730-95c65a4029bb   \n",
       "15  13e0c176-e18b-435a-983b-f81e763837e6   \n",
       "16  1a3e7d64-adbc-4c49-abbe-3f871f3c557a   \n",
       "17  11df5b6f-d134-4195-9cc0-6273e4be67c5   \n",
       "18  1b157958-b600-4aa7-98d6-f711a333d3f7   \n",
       "19  24f7c131-9d07-4251-83fc-20ab9079e326   \n",
       "\n",
       "                                     PredictionString  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4   0.99937195   0   0 103 180 0.95054185   22    ...  \n",
       "5                                                 NaN  \n",
       "6                          0.49112582   0  21 460 991  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                          0.26053515 270 542 213 246  \n",
       "10                                                NaN  \n",
       "11  0.53055733 149 352 281 496 0.42007858 620 281 ...  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15  0.9999367 448 384 129 257 0.26660335 934 890 1...  \n",
       "16                           0.377284 214 345 304 493  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2ff95f9e-bada-492a-8e17-ccec1781b9e7</td>\n",
       "      <td>0.49112582   0  21 460 991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId            PredictionString\n",
       "6  2ff95f9e-bada-492a-8e17-ccec1781b9e7  0.49112582   0  21 460 991"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.loc[submission_df['patientId']=='2ff95f9e-bada-492a-8e17-ccec1781b9e7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>2ff95f9e-bada-492a-8e17-ccec1781b9e7</td>\n",
       "      <td>0.49112582   0  21 460 991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 patientId            PredictionString\n",
       "2742  2ff95f9e-bada-492a-8e17-ccec1781b9e7  0.49112582   0  21 460 991"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission2_df.loc[sample_submission2_df['patientId']=='2ff95f9e-bada-492a-8e17-ccec1781b9e7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219f3fa2d8ec4e97be7e1d24fe99c59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(submission_df.iterrows(), total=submission_df.shape[0]):\n",
    "    pId = row['patientId']\n",
    "    pred = row['PredictionString']\n",
    "    sample_submission2_df.loc[sample_submission2_df['patientId']==pId, 'PredictionString'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000a175-0e68-4ca4-b1af-167204a7e0bc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0005d3cc-3c3f-40b9-93c3-46231c3eb813</td>\n",
       "      <td>0.9986475   24    1 1025  987 0.99259627  17  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000686d7-f4fc-448d-97a0-44fa9c5d3aa6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000e3a7d-c0ca-4349-bb26-5af2d8993c3d</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00100a24-854d-423d-a092-edcf6179e061</td>\n",
       "      <td>0.5059814 556 367 211 462 0.20431605 447 525 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0015597f-2d69-4bc7-b642-5b5e01534676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001b0c51-c7b3-45c1-9c17-fa7594cab96e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0022bb50-bf6c-4185-843e-403a9cc1ea80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00271e8e-aea8-4f0a-8a34-3025831f1079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0028450f-5b8e-4695-9416-8340b6f686b0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>002bcde0-d8da-4931-ab04-5d724e30261b</td>\n",
       "      <td>0.29353708 569 450 297 454 0.2867135 162 368 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>002fcb77-ef76-4626-ab34-5070f15c20db</td>\n",
       "      <td>1.0   22    7 1044  984 0.9983443 448 384 129 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>003206b4-bd4a-4684-8d49-76f4cb713a30</td>\n",
       "      <td>0.66547394 581 554 399 742 0.44082537 400 345 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00330f7f-d114-4eb2-9c6e-558eeb3084a1</td>\n",
       "      <td>0.23709674 550 347 189 395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00342ae8-ff81-4229-adf6-6a2ab711707b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>003d17f0-bd8a-485c-bc8b-daec33f53efa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>003dba79-1b1d-4713-add8-d72c54074f8a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>003ec9e3-512e-4f6e-923d-daa9f9f3db9a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>003fbda2-ba55-4714-a03a-83f15bec19e4</td>\n",
       "      <td>0.40333694 201 350 319 496 0.35035875 593 247 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0041fc67-793c-4129-a952-ea3fb821b445</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               patientId  \\\n",
       "0   0000a175-0e68-4ca4-b1af-167204a7e0bc   \n",
       "1   0005d3cc-3c3f-40b9-93c3-46231c3eb813   \n",
       "2   000686d7-f4fc-448d-97a0-44fa9c5d3aa6   \n",
       "3   000e3a7d-c0ca-4349-bb26-5af2d8993c3d   \n",
       "4   00100a24-854d-423d-a092-edcf6179e061   \n",
       "5   0015597f-2d69-4bc7-b642-5b5e01534676   \n",
       "6   001b0c51-c7b3-45c1-9c17-fa7594cab96e   \n",
       "7   0022bb50-bf6c-4185-843e-403a9cc1ea80   \n",
       "8   00271e8e-aea8-4f0a-8a34-3025831f1079   \n",
       "9   0028450f-5b8e-4695-9416-8340b6f686b0   \n",
       "10  002bcde0-d8da-4931-ab04-5d724e30261b   \n",
       "11  002fcb77-ef76-4626-ab34-5070f15c20db   \n",
       "12  003206b4-bd4a-4684-8d49-76f4cb713a30   \n",
       "13  00330f7f-d114-4eb2-9c6e-558eeb3084a1   \n",
       "14  00342ae8-ff81-4229-adf6-6a2ab711707b   \n",
       "15  003d17f0-bd8a-485c-bc8b-daec33f53efa   \n",
       "16  003dba79-1b1d-4713-add8-d72c54074f8a   \n",
       "17  003ec9e3-512e-4f6e-923d-daa9f9f3db9a   \n",
       "18  003fbda2-ba55-4714-a03a-83f15bec19e4   \n",
       "19  0041fc67-793c-4129-a952-ea3fb821b445   \n",
       "\n",
       "                                     PredictionString  \n",
       "0                                                 NaN  \n",
       "1   0.9986475   24    1 1025  987 0.99259627  17  ...  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4   0.5059814 556 367 211 462 0.20431605 447 525 4...  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10  0.29353708 569 450 297 454 0.2867135 162 368 2...  \n",
       "11  1.0   22    7 1044  984 0.9983443 448 384 129 ...  \n",
       "12  0.66547394 581 554 399 742 0.44082537 400 345 ...  \n",
       "13                         0.23709674 550 347 189 395  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18  0.40333694 201 350 319 496 0.35035875 593 247 ...  \n",
       "19                                                NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission2_df[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_submission2_df.to_csv(SUBMISSIONS/'stage2-drop4.2-NoNegatives-2018-10-28 09:25:34.462274 - ordered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit prediction via command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c rsna-pneumonia-detection-challenge -f SUBMISSIONS/sub_name -m \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "428.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
